{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Cài đặt các gói tin + khai báo các thư viện cần thiết"
      ],
      "metadata": {
        "id": "1J9m43aS2FvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_M_7qYva2h1p",
        "outputId": "3e671ae5-931d-4865-f511-3da3c5ea9453"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pymop\n",
            "  Downloading pymop-0.2.4-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pymop) (1.21.6)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.8/dist-packages (from pymop) (1.5)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.8/dist-packages (from autograd->pymop) (0.16.0)\n",
            "Installing collected packages: pymop\n",
            "Successfully installed pymop-0.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymoo==0.3.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwC-oQwI2iyE",
        "outputId": "72e64780-7445-4a95-8652-396131c6fd08"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pymoo==0.3.0\n",
            "  Downloading pymoo-0.3.0.tar.gz (531 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m531.3/531.3 KB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pymop==0.2.4 in /usr/local/lib/python3.8/dist-packages (from pymoo==0.3.0) (0.2.4)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.8/dist-packages (from pymoo==0.3.0) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.8/dist-packages (from pymoo==0.3.0) (1.7.3)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.8/dist-packages (from pymoo==0.3.0) (3.2.2)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.8/dist-packages (from pymop==0.2.4->pymoo==0.3.0) (1.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3->pymoo==0.3.0) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3->pymoo==0.3.0) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3->pymoo==0.3.0) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3->pymoo==0.3.0) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib>=3->pymoo==0.3.0) (1.15.0)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.8/dist-packages (from autograd->pymop==0.2.4->pymoo==0.3.0) (0.16.0)\n",
            "Building wheels for collected packages: pymoo\n",
            "  Building wheel for pymoo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pymoo: filename=pymoo-0.3.0-cp38-cp38-linux_x86_64.whl size=1809552 sha256=693478d81c396931c6ae8e0820378700e55e710f0d4629e6144976dd56e84480\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/92/e4/3d370dbd16e98dc76b5546da134ff51e824db3893f71fbc0e3\n",
            "Successfully built pymoo\n",
            "Installing collected packages: pymoo\n",
            "Successfully installed pymoo-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "# update your projecty root path before running\n",
        "sys.path.insert(0, '/path/to/nsga-net')\n",
        "\n",
        "import os\n",
        "import time\n",
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "import shutil\n",
        "from pymop.problem import Problem\n",
        "from pymoo.optimize import minimize\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils\n",
        "# import torchvision.datasets as dset\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import time\n",
        "\n",
        "from copy import copy\n",
        "from abc import ABC, abstractmethod\n",
        "from collections import OrderedDict\n",
        "\n",
        "from __future__ import print_function\n",
        "from PIL import Image\n",
        "import os.path\n",
        "if sys.version_info[0] == 2:\n",
        "    import cPickle as pickle\n",
        "else:\n",
        "    import pickle\n",
        "\n",
        "import torch.utils.data as data\n",
        "# from .utils import download_url, check_integrity\n",
        "\n",
        "import errno\n",
        "import hashlib\n"
      ],
      "metadata": {
        "id": "v8-LBXsF2ndC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pymoo.algorithms.genetic_algorithm import GeneticAlgorithm\n",
        "from pymoo.docs import parse_doc_string\n",
        "from pymoo.model.individual import Individual\n",
        "from pymoo.model.survival import Survival\n",
        "from pymoo.operators.crossover.point_crossover import PointCrossover\n",
        "from pymoo.operators.mutation.polynomial_mutation import PolynomialMutation\n",
        "from pymoo.operators.sampling.random_sampling import RandomSampling\n",
        "from pymoo.operators.selection.tournament_selection import compare, TournamentSelection\n",
        "from pymoo.util.display import disp_multi_objective\n",
        "from pymoo.util.dominator import Dominator\n",
        "from pymoo.util.non_dominated_sorting import NonDominatedSorting\n",
        "from pymoo.util.randomized_argsort import randomized_argsort"
      ],
      "metadata": {
        "id": "o_rWUvAK5aud"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set cứng các thông số cho chương trình"
      ],
      "metadata": {
        "id": "xN2lhE3V3KdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save = 'GA-BiObj'\n",
        "seed = 0\n",
        "search_space = 'macro'\n",
        "n_blocks = 5\n",
        "n_ops = 9\n",
        "n_cells = 2 \n",
        "n_nodes = 6\n",
        "pop_size = 40\n",
        "n_gens = 30\n",
        "n_offspring = 40\n",
        "init_channels = 24\n",
        "layers = 11\n",
        "epochs = 25\n",
        "device = 'cuda'\n",
        "save = 'search-{}-{}-{}'.format(save, search_space, time.strftime(\"%Y%m%d-%H%M%S\"))"
      ],
      "metadata": {
        "id": "P7fKVT9T3RmD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Định nghĩa các class, hàm cần thiết"
      ],
      "metadata": {
        "id": "X0vXc2kE3wGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_exp_dir(path, scripts_to_save=None):\n",
        "    '''\n",
        "    tạo đường dẫn cho file\n",
        "\n",
        "    path: đường dẫn muốn tạo\n",
        "    scripts_to_save: scripts muốn truyền vào file\n",
        "\n",
        "    '''\n",
        "    if not os.path.exists(path):\n",
        "        os.mkdir(path)\n",
        "    print('Experiment dir : {}'.format(path))\n",
        "\n",
        "    if scripts_to_save is not None:\n",
        "        os.mkdir(os.path.join(path, 'scripts'))\n",
        "        for script in scripts_to_save:\n",
        "            dst_file = os.path.join(path, 'scripts', os.path.basename(script))\n",
        "            shutil.copyfile(script, dst_file)"
      ],
      "metadata": {
        "id": "6QMBxeDp332e"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_exp_dir(save)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkiTK7H-4kMq",
        "outputId": "6dd5f932-2820-421f-f86e-e3e05cb42158"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment dir : search-GA-BiObj-macro-20230106-060525\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_format = '%(asctime)s %(message)s'\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
        "                    format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
        "fh = logging.FileHandler(os.path.join(save, 'log.txt'))\n",
        "fh.setFormatter(logging.Formatter(log_format))\n",
        "logging.getLogger().addHandler(fh)"
      ],
      "metadata": {
        "id": "U5fam02Z4qAf"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def phase_dencode(phase_bit_string):\n",
        "    n = int(np.sqrt(2 * len(phase_bit_string) - 7/4) - 1/2)\n",
        "    genome = []\n",
        "    for i in range(n):\n",
        "        operator = []\n",
        "        for j in range(i + 1):\n",
        "            operator.append(phase_bit_string[int(i * (i + 1) / 2 + j)])\n",
        "        genome.append(operator)\n",
        "    genome.append([phase_bit_string[-1]])\n",
        "    return genome"
      ],
      "metadata": {
        "id": "_p2USbjp4wyk"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(genome):\n",
        "    genotype = []\n",
        "    for gene in genome:\n",
        "        genotype.append(phase_dencode(gene))\n",
        "\n",
        "    return genotype"
      ],
      "metadata": {
        "id": "e6yzLU2m428T"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(ABC):\n",
        "    \"\"\"\n",
        "    Abstract genome decoder class.\n",
        "    \"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def __init__(self, list_genome):\n",
        "        \"\"\"\n",
        "        :param list_genome: genome represented as a list.\n",
        "        \"\"\"\n",
        "        self._genome = list_genome\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_model(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class ChannelBasedDecoder(Decoder):\n",
        "    \"\"\"\n",
        "    Channel based decoder that deals with encapsulating constructor logic.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, list_genome, channels, repeats=None):\n",
        "        \"\"\"\n",
        "        Constructor.\n",
        "        :param list_genome: list, genome describing the connections in a network.\n",
        "        :param channels: list, list of tuples describing the channel size changes.\n",
        "        :param repeats: None | list, list of integers describing how many times to repeat each phase.\n",
        "        \"\"\"\n",
        "        super().__init__(list_genome)\n",
        "\n",
        "        self._model = None\n",
        "\n",
        "        # First, we remove all inactive phases.\n",
        "        self._genome = self.get_effective_genome(list_genome)\n",
        "        self._channels = channels[:len(self._genome)]\n",
        "\n",
        "        # Use the provided repeats list, or a list of all ones (only repeat each phase once).\n",
        "        if repeats is not None:\n",
        "            # First select only the repeats that are active in the list_genome.\n",
        "            active_repeats = []\n",
        "            for idx, gene in enumerate(list_genome):\n",
        "                if phase_active(gene):\n",
        "                    active_repeats.append(repeats[idx])\n",
        "\n",
        "            self.adjust_for_repeats(active_repeats)\n",
        "        else:\n",
        "            # Each phase only repeated once.\n",
        "            self._repeats = [1 for _ in self._genome]\n",
        "\n",
        "        # If we had no active nodes, our model is just the identity, and we stop constructing.\n",
        "        if not self._genome:\n",
        "            self._model = Identity()\n",
        "\n",
        "        # print(list_genome)\n",
        "\n",
        "    def adjust_for_repeats(self, repeats):\n",
        "        \"\"\"\n",
        "        Adjust for repetition of phases.\n",
        "        :param repeats:\n",
        "        \"\"\"\n",
        "        self._repeats = repeats\n",
        "\n",
        "        # Adjust channels and genome to agree with repeats.\n",
        "        repeated_genome = []\n",
        "        repeated_channels = []\n",
        "        for i, repeat in enumerate(self._repeats):\n",
        "            for j in range(repeat):\n",
        "                if j == 0:\n",
        "                    # This is the first instance of this repeat, we need to use the (in, out) channel convention.\n",
        "                    repeated_channels.append((self._channels[i][0], self._channels[i][1]))\n",
        "                else:\n",
        "                    # This is not the first instance, use the (out, out) convention.\n",
        "                    repeated_channels.append((self._channels[i][1], self._channels[i][1]))\n",
        "\n",
        "                repeated_genome.append(self._genome[i])\n",
        "\n",
        "        self._genome = repeated_genome\n",
        "        self._channels = repeated_channels\n",
        "\n",
        "    def build_layers(self, phases):\n",
        "        \"\"\"\n",
        "        Build up the layers with transitions.\n",
        "        :param phases: list of phases\n",
        "        :return: list of layers (the model).\n",
        "        \"\"\"\n",
        "        layers = []\n",
        "        last_phase = phases.pop()\n",
        "        for phase, repeat in zip(phases, self._repeats):\n",
        "            for _ in range(repeat):\n",
        "                layers.append(phase)\n",
        "            layers.append(nn.MaxPool2d(kernel_size=2, stride=2))  # TODO: Generalize this, or consider a new genome.\n",
        "\n",
        "        layers.append(last_phase)\n",
        "        return layers\n",
        "\n",
        "    @staticmethod\n",
        "    def get_effective_genome(genome):\n",
        "        \"\"\"\n",
        "        Get only the parts of the genome that are active.\n",
        "        :param genome: list, represents the genome\n",
        "        :return: list\n",
        "        \"\"\"\n",
        "        return [gene for gene in genome if phase_active(gene)]\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_model(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class HourGlassDecoder(Decoder):\n",
        "    \"\"\"\n",
        "    Decoder that deals with HourGlass-type networks.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, genome, n_stacks, out_feature_maps):\n",
        "        \"\"\"\n",
        "        Constructor.\n",
        "        :param genome: list, list of ints.\n",
        "        :param n_stacks: int, number of hourglasses to use.\n",
        "        :param out_feature_maps: int, number of output feature maps.\n",
        "        \"\"\"\n",
        "        super().__init__(genome)\n",
        "\n",
        "        self.n_stacks = n_stacks\n",
        "        self.out_feature_maps = out_feature_maps\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_model(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    @staticmethod\n",
        "    @abstractmethod\n",
        "    def check_genome(genome):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class LOSHourGlassDecoder(HourGlassDecoder, nn.Module):\n",
        "    \"\"\"\n",
        "    Line of sight HourGlass decoder.\n",
        "    \"\"\"\n",
        "\n",
        "    STEP_TOLERANCE = 2  # A network can step as much as\n",
        "    GENE_LB = 0  # Gene must be greater than this value.\n",
        "    GENE_UB = 6  # Gene must be less than this value.\n",
        "\n",
        "    def __init__(self, genome, n_stacks, out_feature_maps, pre_hourglass_channels=32, hourglass_channels=64):\n",
        "        \"\"\"\n",
        "        Constructor.\n",
        "        :param genome: list, list of ints satisfying properties defined in self.valid_genome.\n",
        "        :param n_stacks: int, number of hourglasses to use.\n",
        "        :param out_feature_maps, int, number of output feature maps.\n",
        "        \"\"\"\n",
        "        HourGlassDecoder.__init__(self, genome, n_stacks, out_feature_maps)\n",
        "        nn.Module.__init__(self)\n",
        "\n",
        "        self.pre_hourglass_channels = pre_hourglass_channels\n",
        "        self.hourglass_channels = hourglass_channels\n",
        "\n",
        "        self.check_genome(genome)\n",
        "\n",
        "        # Initial resolution reducing, takes 256 x 256 to 64 x 64\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.Conv2d(3, self.pre_hourglass_channels, kernel_size=7, stride=2, padding=3, bias=True),\n",
        "            nn.BatchNorm2d(self.pre_hourglass_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            HourGlassResidual(self.pre_hourglass_channels, self.pre_hourglass_channels)\n",
        "        )\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.secondary = nn.Sequential(\n",
        "            HourGlassResidual(self.pre_hourglass_channels, self.pre_hourglass_channels),\n",
        "            HourGlassResidual(self.pre_hourglass_channels, self.hourglass_channels)\n",
        "        )\n",
        "\n",
        "        #\n",
        "        # Evolved part follows.\n",
        "        #\n",
        "        graph = LOSComputationGraph(genome)  # The evolved computation graph.\n",
        "        hg_channels = self.hourglass_channels * LOSHourGlassBlock.EXPANSION  # Number of channels output by the hourglass.\n",
        "\n",
        "        # List of hourglasses, deep copy of hourglass constructed above.\n",
        "        hourglasses = [LOSHourGlassBlock(graph, self.hourglass_channels, hg_channels)]\n",
        "\n",
        "        # Lin layers run on the output of the hourglass.\n",
        "        first_lin = [Lin(hg_channels, hg_channels)]\n",
        "        second_lin = [Lin(hg_channels, self.hourglass_channels)]\n",
        "\n",
        "        # 1x1 convs to adjust channels to fit number of scoremaps.\n",
        "        to_score_map = [nn.Conv2d(self.hourglass_channels, out_feature_maps, kernel_size=1, bias=True)]\n",
        "        # 1x1 convs to adjust scoremap back to appropriate feature map count.\n",
        "        from_score_map = [nn.Conv2d(out_feature_maps, self.hourglass_channels + self.pre_hourglass_channels, kernel_size=1, bias=True)]\n",
        "\n",
        "        # 1x1 convs for the skip connection that skips the hourglass.\n",
        "        skip_convs = [nn.Conv2d(self.hourglass_channels + self.pre_hourglass_channels, self.hourglass_channels + self.pre_hourglass_channels,\n",
        "                                kernel_size=1, bias=True)]\n",
        "\n",
        "        skip_channels = self.pre_hourglass_channels\n",
        "\n",
        "        #\n",
        "        # The above and proceeding code is overly complex to deal with the fact that the first skip connection will\n",
        "        # have less channels than the rest of the network, as specified in the original implementation.\n",
        "        #\n",
        "\n",
        "        for i in range(1, n_stacks):\n",
        "            hourglasses.append(LOSHourGlassBlock(graph, self.hourglass_channels + skip_channels, hg_channels))\n",
        "            first_lin.append(Lin(hg_channels, hg_channels))\n",
        "\n",
        "            to_score_map.append(nn.Conv2d(self.hourglass_channels, out_feature_maps, kernel_size=1, bias=True))\n",
        "            second_lin.append(Lin(hg_channels, self.hourglass_channels))\n",
        "\n",
        "            # We only need go back to the original channel sizes from the score maps n - 1 times.\n",
        "            if i < n_stacks - 1:\n",
        "                skip_convs.append(nn.Conv2d(hg_channels, hg_channels, kernel_size=1, bias=True))\n",
        "                from_score_map.append(nn.Conv2d(out_feature_maps, hg_channels, kernel_size=1,\n",
        "                                                bias=True))\n",
        "\n",
        "            skip_channels = self.hourglass_channels\n",
        "\n",
        "        # Register everything by converting to ModuleLists.\n",
        "        self.hourglasses = nn.ModuleList(hourglasses)\n",
        "        self.first_lin = nn.ModuleList(first_lin)\n",
        "        self.to_score_map = nn.ModuleList(to_score_map)\n",
        "        self.from_score_map = nn.ModuleList(from_score_map)\n",
        "        self.second_lin = nn.ModuleList(second_lin)\n",
        "        self.skip_convs = nn.ModuleList(skip_convs)\n",
        "\n",
        "    @staticmethod\n",
        "    def check_genome(genome):\n",
        "        \"\"\"\n",
        "        Make sure the genome is valid.\n",
        "        :param genome: list, list of ints, representing the genome.\n",
        "        :raises AssertionError: if genome is not valid.\n",
        "        \"\"\"\n",
        "        assert isinstance(genome[0], int), \"Genome should be a list of integers.\"\n",
        "\n",
        "        for gene in genome:\n",
        "            assert LOSHourGlassDecoder.GENE_LB < gene < LOSHourGlassDecoder.GENE_UB, \\\n",
        "                \"{} is an invalid gene value, must be in range [{}, {}]\".format(gene,\n",
        "                                                                                LOSHourGlassDecoder.GENE_LB,\n",
        "                                                                                LOSHourGlassDecoder.GENE_UB)\n",
        "        for i in range(len(genome) - 1):\n",
        "            step = abs(genome[i] - genome[i + 1])\n",
        "            assert step <= LOSHourGlassDecoder.STEP_TOLERANCE, \\\n",
        "                \"Attempted to step {} resolutions, cannot step more than 2 resolutions.\".format(step)\n",
        "\n",
        "    def get_model(self):\n",
        "        \"\"\"\n",
        "        In other decoders, we'd return a module object, but since self is an nn.Module, we return self.\n",
        "        :return: self\n",
        "        \"\"\"\n",
        "        return self\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward operation.\n",
        "        :param x: Variable, input\n",
        "        :return: list, list of Variables, intermediate and final score maps.\n",
        "        \"\"\"\n",
        "        maps = []\n",
        "\n",
        "        x = self.initial(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        skip = x.clone()\n",
        "\n",
        "        x = self.secondary(x)\n",
        "\n",
        "        for i in range(self.n_stacks):\n",
        "            y = self.hourglasses[i](x)\n",
        "            y = self.first_lin[i](y)\n",
        "            y = self.second_lin[i](y)\n",
        "\n",
        "            next_skip = y.clone()\n",
        "\n",
        "            score_map = self.to_score_map[i](y)\n",
        "\n",
        "            maps.append(score_map)\n",
        "\n",
        "            # We only need to map back from the score feature maps and do skip connection n - 1 times.\n",
        "            if i < self.n_stacks - 1:\n",
        "                z = self.from_score_map[i](score_map)\n",
        "                a = torch.cat((y, skip), dim=1)\n",
        "                a = self.skip_convs[i](a)\n",
        "\n",
        "                x = z + a\n",
        "\n",
        "            skip = next_skip\n",
        "\n",
        "        return maps\n",
        "\n",
        "\n",
        "class Lin(nn.Module):\n",
        "    \"\"\"\n",
        "    \"Lin\" layer as implemented in: https://github.com/umich-vl/pose-hg-demo/blob/master/stacked-hourglass-model.lua\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        \"\"\"\n",
        "        Constructor.\n",
        "        :param in_channels: int, input channels.\n",
        "        :param out_channels: int, desired output channels.\n",
        "        \"\"\"\n",
        "        super(Lin, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=True),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "class LOSHourGlassBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    HourGlassBlock, repeated in an hourglass-type network.\n",
        "    \"\"\"\n",
        "\n",
        "    EXPANSION = 2  # Hour glass block will increase channels by a factor of 2.\n",
        "\n",
        "    def __init__(self, graph, in_channels, out_channels, operating_channels=64):\n",
        "        \"\"\"\n",
        "        Constructor.\n",
        "        :param graph: decoder.LOSComputationGraph, represents the computation flow.\n",
        "        :param in_channels: int, number of input channels.\n",
        "        :param out_channels: int, number of output channels.\n",
        "        \"\"\"\n",
        "        super(LOSHourGlassBlock, self).__init__()\n",
        "\n",
        "        self.operating_channels = operating_channels\n",
        "\n",
        "        self.graph = graph\n",
        "        samplers = []\n",
        "        nodes, _ = zip(*self.graph.items())\n",
        "        nodes = [None] + list(nodes) + [None]  # Append none's to downsample input and upsample output if needed.\n",
        "        for i in range(len(nodes[:-1])):\n",
        "            samplers.append(self.make_sampling(nodes[i], nodes[i + 1]))\n",
        "\n",
        "        self.samplers = nn.ModuleList(samplers)\n",
        "\n",
        "        skip_ops = []  # HourGlassResiduals for the skip connections\n",
        "        for node in graph.keys():\n",
        "            if node.residual:\n",
        "                skip_ops.append(HourGlassResidual(self.operating_channels, self.operating_channels))\n",
        "\n",
        "            else:\n",
        "                skip_ops.append(None)  # Filler to make the indices match\n",
        "\n",
        "        last_node = list(graph.keys())[-1]\n",
        "        res = last_node.residual_node\n",
        "        if res:\n",
        "            # If the last node receives a residual, we need to change the operation to output the right channel size.\n",
        "            skip_ops[res.idx] = HourGlassResidual(self.operating_channels, out_channels)\n",
        "\n",
        "        self.skip_ops = nn.ModuleList(skip_ops)\n",
        "\n",
        "        path_ops = [HourGlassResidual(in_channels, self.operating_channels)]\n",
        "        for i in range(len(graph) - 2):\n",
        "            path_ops.append(HourGlassResidual(self.operating_channels, self.operating_channels))\n",
        "\n",
        "        path_ops.append(HourGlassResidual(self.operating_channels, out_channels))\n",
        "\n",
        "        self.path_ops = nn.ModuleList(path_ops)\n",
        "\n",
        "    @staticmethod\n",
        "    def make_sampling(prev_node, next_node):\n",
        "        \"\"\"\n",
        "        Determine the factor of up/down sampling needed to move between two nodes.\n",
        "        :param prev_node: LOSComputationGraph.Node | None.\n",
        "        :param next_node: LOSComputationGraph.Node.\n",
        "        :return: nn.MaxPool2d | nn.Upsample\n",
        "        \"\"\"\n",
        "        if prev_node is None:\n",
        "            # We're dealing with the first node (idx 0) so we need a placeholder node.\n",
        "            prev_node = LOSComputationGraph.Node(1, -1)\n",
        "\n",
        "        if next_node is None:\n",
        "            next_node = LOSComputationGraph.Node(1, -1)\n",
        "\n",
        "        if prev_node.resolution == next_node.resolution:\n",
        "            # Nothing to be done.\n",
        "            return Identity()\n",
        "\n",
        "        elif prev_node.resolution > next_node.resolution:\n",
        "            # We need to downsample.\n",
        "            s = int(prev_node.resolution / next_node.resolution)\n",
        "            return nn.MaxPool2d(kernel_size=2, stride=s)\n",
        "\n",
        "        else:\n",
        "            # We need to upsample.\n",
        "            f = int(next_node.resolution / prev_node.resolution)\n",
        "            return nn.Upsample(scale_factor=f, mode=\"nearest\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        residuals = [None for _ in range(len(self.graph))]\n",
        "\n",
        "        for i, (node, _) in enumerate(self.graph.items()):\n",
        "            x = self.samplers[i](x)\n",
        "\n",
        "            x = self.path_ops[i](x)\n",
        "\n",
        "            if node.residual:\n",
        "                residuals[i] = self.skip_ops[i](x.clone())\n",
        "\n",
        "            res = node.residual_node\n",
        "            if res:\n",
        "                # Current node receives a residual connection.\n",
        "                x += residuals[res.idx]\n",
        "                residuals[res.idx] = None  # Free some memory, we'll never need this again.\n",
        "\n",
        "        return self.samplers[-1](x)\n",
        "\n",
        "\n",
        "class LOSComputationGraph:\n",
        "    \"\"\"\n",
        "    Graph to hold information about the computation going on in\n",
        "    \"\"\"\n",
        "    class Node:\n",
        "        \"\"\"\n",
        "        Node to hold information.\n",
        "        \"\"\"\n",
        "        def __init__(self, resolution, idx, residual=False):\n",
        "            \"\"\"\n",
        "            Constructor.\n",
        "            :param resolution: int, the resolution of the image at this point.\n",
        "            :param idx: int, the index of the node in the graph (feed-forward, so this is ok).\n",
        "            :param residual: bool, true if output of this node is needed at some point later in the graph.\n",
        "            \"\"\"\n",
        "            self.resolution, self.idx, self.residual = resolution, idx, residual\n",
        "            self.residual_node = None  # If this node receives a residual, store it here.\n",
        "\n",
        "        def __repr__(self):\n",
        "            residual_str = \", saves residual\" if self.residual else \"\"\n",
        "            return \"<Node index: {} resolution: {}\".format(self.idx, self.resolution) + residual_str + \">\"\n",
        "\n",
        "        def __str__(self):\n",
        "            return self.__repr__()\n",
        "\n",
        "        def __lt__(self, other):\n",
        "            assert isinstance(other, LOSComputationGraph.Node)\n",
        "            return self.idx < other.idx\n",
        "\n",
        "    def __init__(self, genome, under_connect=True):\n",
        "        \"\"\"\n",
        "        Make the computation graph specified by the genoms.\n",
        "        :param genome: list, list of ints representing a genome.\n",
        "        \"\"\"\n",
        "        self.graph = LOSComputationGraph.make_graph(genome, under_connect)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.graph)\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self.graph.__iter__()\n",
        "\n",
        "    def items(self):\n",
        "        return self.graph.items()\n",
        "\n",
        "    def keys(self):\n",
        "        return self.graph.keys()\n",
        "\n",
        "    def values(self):\n",
        "        return self.graph.values()\n",
        "\n",
        "    def get_residual(self, node):\n",
        "        \"\"\"\n",
        "        Determines if a particular node in the graph gets a residual connection.\n",
        "        :param node: LOSComputationGraph.Node.\n",
        "        :return: LOSComputationGraph.Node | None\n",
        "        \"\"\"\n",
        "        if node in self.graph:\n",
        "            for dep in self.graph[node]:\n",
        "                if dep.resolution == node.resolution and dep.residual:\n",
        "                    return dep\n",
        "\n",
        "        return None\n",
        "\n",
        "    @staticmethod\n",
        "    def make_graph(genome, under_connect=True):\n",
        "        \"\"\"\n",
        "        Make the computation graph.\n",
        "        The is not exactly an adjacency list... The normal forward path through the network is as expected, but the\n",
        "            skip connections are only listed in the receiving nodes, rather than the sending nodes.\n",
        "            This makes things much easier when actually forward propagating.\n",
        "        :param genome: list, list of ints representing a genome.\n",
        "        :param under_connect: bool, if false, we will not allow \"under connections\".\n",
        "            Where an under connection connects nodes that may occur below the current path. Ex:\n",
        "            | X ----->  X ----->  X\n",
        "            |   X --> X .. X --> X\n",
        "            |     X  ......  X\n",
        "            Where arrows are the normal residual connections and the dots are the optional under connections.\n",
        "        :return: OrderedDict, dict of lists, adjacency list describing the computation graph.\n",
        "        \"\"\"\n",
        "        adj = OrderedDict()\n",
        "\n",
        "        nodes = [LOSComputationGraph.Node(pow(2, -(gene - 1)), i) for i, gene in enumerate(genome)]\n",
        "\n",
        "        # Construct the initial path through the graph, each node is connected to the one at the index in front of it.\n",
        "        # Read as \"Gene i\" and \"Gene i plus one\".\n",
        "        for i, (gene_i, gene_ipo) in enumerate(zip(nodes, nodes[1:])):\n",
        "            adj[gene_i] = [gene_ipo]\n",
        "\n",
        "        adj[nodes[-1]] = []\n",
        "\n",
        "        previous_resolutions = {}\n",
        "        previous_node = nodes[0]\n",
        "        for node, adj_list in adj.items():\n",
        "            if node.resolution in previous_resolutions:\n",
        "                # We have found a node that occurred before the current one with the same resolution.\n",
        "\n",
        "                if previous_node.resolution < node.resolution or \\\n",
        "                   previous_node.resolution > node.resolution and under_connect:\n",
        "                    # Either we upsampled or downsampled. We always mark a residual and update the previous resolution\n",
        "                    # is we upsample. If we're allowing connections under the path, we do the same.\n",
        "                    previous_resolutions[node.resolution].residual = True\n",
        "                    node.residual_node = previous_resolutions[node.resolution]\n",
        "                    previous_resolutions[node.resolution] = node\n",
        "\n",
        "                else:\n",
        "                    # There was no change in resolution, just update previous_resolutions at this value to be\n",
        "                    # the current node.\n",
        "                    previous_resolutions[node.resolution] = node\n",
        "\n",
        "            else:\n",
        "                # We did not find a node before the current one that had its particular resolution.\n",
        "                previous_resolutions[node.resolution] = node\n",
        "\n",
        "            previous_node = node\n",
        "\n",
        "        return adj\n",
        "\n",
        "\n",
        "class HourGlassResidual(nn.Module):\n",
        "    \"\"\"\n",
        "    Hour glass residual, As defined in https://arxiv.org/pdf/1603.06937.pdf.\n",
        "    Code converted from original lua: https://github.com/umich-vl/pose-hg-demo/blob/master/residual.lua\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(HourGlassResidual, self).__init__()\n",
        "\n",
        "        # 1x1 convolution to make the residual connection's channels match the output channels.\n",
        "        self.skip_layer = Identity() if in_channels == out_channels else \\\n",
        "            nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=True), nn.BatchNorm2d(out_channels))\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels // 2, kernel_size=1, bias=True),\n",
        "            nn.BatchNorm2d(out_channels // 2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels // 2, out_channels // 2, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "            nn.BatchNorm2d(out_channels // 2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels // 2, out_channels, kernel_size=1, bias=True),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Apply forward propagation operation.\n",
        "        :param x: Variable, input.\n",
        "        :return: Variable\n",
        "        \"\"\"\n",
        "        residual = x\n",
        "        out = self.model(x)\n",
        "        return out + self.skip_layer(residual)\n",
        "\n",
        "\n",
        "class ResidualGenomeDecoder(ChannelBasedDecoder):\n",
        "    \"\"\"\n",
        "    Genetic CNN genome decoder with residual bit.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, list_genome, channels, preact=False, repeats=None):\n",
        "        \"\"\"\n",
        "        Constructor.\n",
        "        :param list_genome: list, genome describing the connections in a network.\n",
        "        :param channels: list, list of tuples describing the channel size changes.\n",
        "        :param repeats: None | list, list of integers describing how many times to repeat each phase.\n",
        "        \"\"\"\n",
        "        super().__init__(list_genome, channels, repeats=repeats)\n",
        "\n",
        "        if self._model is not None:\n",
        "            return  # Exit if the parent constructor set the model.\n",
        "\n",
        "        # Build up the appropriate number of phases.\n",
        "        phases = []\n",
        "        for idx, (gene, (in_channels, out_channels)) in enumerate(zip(self._genome, self._channels)):\n",
        "            phases.append(ResidualPhase(gene, in_channels, out_channels, idx, preact=preact))\n",
        "\n",
        "        self._model = nn.Sequential(*self.build_layers(phases))\n",
        "\n",
        "    def get_model(self):\n",
        "        \"\"\"\n",
        "        :return: nn.Module\n",
        "        \"\"\"\n",
        "        return self._model\n",
        "\n",
        "\n",
        "class ResidualPhase(nn.Module):\n",
        "    \"\"\"\n",
        "    Residual Genome phase.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, gene, in_channels, out_channels, idx, preact=False):\n",
        "        \"\"\"\n",
        "        Constructor.\n",
        "        :param gene: list, element of genome describing connections in this phase.\n",
        "        :param in_channels: int, number of input channels.\n",
        "        :param out_channels: int, number of output channels.\n",
        "        :param idx: int, index in the network.\n",
        "        :param preact: should we use the preactivation scheme?\n",
        "        \"\"\"\n",
        "        super(ResidualPhase, self).__init__()\n",
        "\n",
        "        self.channel_flag = in_channels != out_channels  # Flag to tell us if we need to increase channel size.\n",
        "        self.first_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1 if idx != 0 else 3, stride=1, bias=False)\n",
        "        self.dependency_graph = ResidualPhase.build_dependency_graph(gene)\n",
        "\n",
        "        if preact:\n",
        "            node_constructor = PreactResidualNode\n",
        "\n",
        "        else:\n",
        "            node_constructor = ResidualNode\n",
        "\n",
        "        nodes = []\n",
        "        for i in range(len(gene)):\n",
        "            if len(self.dependency_graph[i + 1]) > 0:\n",
        "                nodes.append(node_constructor(out_channels, out_channels))\n",
        "            else:\n",
        "                nodes.append(None)  # Module list will ignore NoneType.\n",
        "\n",
        "        self.nodes = nn.ModuleList(nodes)\n",
        "\n",
        "        #\n",
        "        # At this point, we know which nodes will be receiving input from where.\n",
        "        # So, we build the 1x1 convolutions that will deal with the depth-wise concatenations.\n",
        "        #\n",
        "        conv1x1s = [Identity()] + [Identity() for _ in range(max(self.dependency_graph.keys()))]\n",
        "        for node_idx, dependencies in self.dependency_graph.items():\n",
        "            if len(dependencies) > 1:\n",
        "                conv1x1s[node_idx] = \\\n",
        "                    nn.Conv2d(len(dependencies) * out_channels, out_channels, kernel_size=1, bias=False)\n",
        "\n",
        "        self.processors = nn.ModuleList(conv1x1s)\n",
        "        self.out = nn.Sequential(\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def build_dependency_graph(gene):\n",
        "        \"\"\"\n",
        "        Build a graph describing the connections of a phase.\n",
        "        \"Repairs\" made are as follows:\n",
        "            - If a node has no input, but gives output, connect it to the input node (index 0 in outputs).\n",
        "            - If a node has input, but no output, connect it to the output node (value returned from forward method).\n",
        "        :param gene: gene describing the phase connections.\n",
        "        :return: dict\n",
        "        \"\"\"\n",
        "        graph = {}\n",
        "        residual = gene[-1][0] == 1\n",
        "\n",
        "        # First pass, build the graph without repairs.\n",
        "        graph[1] = []\n",
        "        for i in range(len(gene) - 1):\n",
        "            graph[i + 2] = [j + 1 for j in range(len(gene[i])) if gene[i][j] == 1]\n",
        "\n",
        "        graph[len(gene) + 1] = [0] if residual else []\n",
        "\n",
        "        # Determine which nodes, if any, have no inputs and/or outputs.\n",
        "        no_inputs = []\n",
        "        no_outputs = []\n",
        "        for i in range(1, len(gene) + 1):\n",
        "            if len(graph[i]) == 0:\n",
        "                no_inputs.append(i)\n",
        "\n",
        "            has_output = False\n",
        "            for j in range(i + 1, len(gene) + 2):\n",
        "                if i in graph[j]:\n",
        "                    has_output = True\n",
        "                    break\n",
        "\n",
        "            if not has_output:\n",
        "                no_outputs.append(i)\n",
        "\n",
        "        for node in no_outputs:\n",
        "            if node not in no_inputs:\n",
        "                # No outputs, but has inputs. Connect to output node.\n",
        "                graph[len(gene) + 1].append(node)\n",
        "\n",
        "        for node in no_inputs:\n",
        "            if node not in no_outputs:\n",
        "                # No inputs, but has outputs. Connect to input node.\n",
        "                graph[node].append(0)\n",
        "\n",
        "        return graph\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.channel_flag:\n",
        "            x = self.first_conv(x)\n",
        "\n",
        "        outputs = [x]\n",
        "\n",
        "        for i in range(1, len(self.nodes) + 1):\n",
        "            if not self.dependency_graph[i]:  # Empty list, no outputs to give.\n",
        "                outputs.append(None)\n",
        "\n",
        "            else:\n",
        "                outputs.append(self.nodes[i - 1](self.process_dependencies(i, outputs)))\n",
        "\n",
        "        return self.out(self.process_dependencies(len(self.nodes) + 1, outputs))\n",
        "\n",
        "    def process_dependencies(self, node_idx, outputs):\n",
        "        \"\"\"\n",
        "        Process dependencies with a depth-wise concatenation and\n",
        "        :param node_idx: int,\n",
        "        :param outputs: list, current outputs\n",
        "        :return: Variable\n",
        "        \"\"\"\n",
        "        return self.processors[node_idx](torch.cat([outputs[i] for i in self.dependency_graph[node_idx]], dim=1))\n",
        "\n",
        "\n",
        "class ResidualNode(nn.Module):\n",
        "    \"\"\"\n",
        "    Basic computation unit.\n",
        "    Does convolution, batchnorm, and relu (in this order).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1,\n",
        "                 kernel_size=3, padding=1, bias=False):\n",
        "        \"\"\"\n",
        "        Constructor.\n",
        "        Default arguments preserve dimensionality of input.\n",
        "        :param in_channels: input to the node.\n",
        "        :param out_channels: output channels from the node.\n",
        "        :param stride: stride of convolution, default 1.\n",
        "        :param kernel_size: size of convolution kernel, default 3.\n",
        "        :param padding: amount of zero padding, default 1.\n",
        "        :param bias: true to use bias, false to not.\n",
        "        \"\"\"\n",
        "        super(ResidualNode, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Apply forward propagation operation.\n",
        "        :param x: Variable, input.\n",
        "        :return: Variable.\n",
        "        \"\"\"\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "class PreactResidualNode(nn.Module):\n",
        "    \"\"\"\n",
        "    Basic computation unit.\n",
        "    Does batchnorm, relu, and convolution (in this order).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1,\n",
        "                 kernel_size=3, padding=1, bias=False):\n",
        "        \"\"\"\n",
        "        Constructor.\n",
        "        Default arguments preserve dimensionality of input.\n",
        "        :param in_channels: input to the node.\n",
        "        :param out_channels: output channels from the node.\n",
        "        :param stride: stride of convolution, default 1.\n",
        "        :param kernel_size: size of convolution kernel, default 3.\n",
        "        :param padding: amount of zero padding, default 1.\n",
        "        :param bias: true to use bias, false to not.\n",
        "        \"\"\"\n",
        "        super(PreactResidualNode, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Apply forward propagation operation.\n",
        "        :param x: Variable, input.\n",
        "        :return: Variable.\n",
        "        \"\"\"\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "class VariableGenomeDecoder(ChannelBasedDecoder):\n",
        "    \"\"\"\n",
        "    Residual decoding with extra integer for type of node inside the phase.\n",
        "    This genome decoder produces networks that are a superset of ResidualGenomeDecoder networks.\n",
        "    \"\"\"\n",
        "    RESIDUAL = 0\n",
        "    PREACT_RESIDUAL = 1\n",
        "    DENSE = 2\n",
        "\n",
        "    def __init__(self, list_genome, channels, repeats=None):\n",
        "        \"\"\"\n",
        "        Constructor.\n",
        "        :param list_genome: list, genome describing the connections in a network, and the type of phase.\n",
        "        :param channels: list, list of tuples describing the channel size changes.\n",
        "        :param repeats: None | list, list of integers describing how many times to repeat each phase.\n",
        "        \"\"\"\n",
        "        phase_types = [gene.pop() for gene in list_genome]\n",
        "        genome_copy = copy(list_genome)  # We can't guarantee the genome won't be changed in the parent constructor.\n",
        "\n",
        "        super().__init__(list_genome, channels, repeats=repeats)\n",
        "\n",
        "        if self._model is not None:\n",
        "            return  # Exit if the parent constructor set the model.\n",
        "\n",
        "        # Adjust the types for repeats and inactive phases.\n",
        "        self._types = self.adjust_types(genome_copy, phase_types)\n",
        "\n",
        "        phases = []\n",
        "        for idx, (gene, (in_channels, out_channels), phase_type) in enumerate(zip(self._genome,\n",
        "                                                                                  self._channels,\n",
        "                                                                                  self._types)):\n",
        "            if phase_type == self.RESIDUAL:\n",
        "                phases.append(ResidualPhase(gene, in_channels, out_channels, idx))\n",
        "\n",
        "            elif phase_type == self.PREACT_RESIDUAL:\n",
        "                phases.append(ResidualPhase(gene, in_channels, out_channels, idx, preact=True))\n",
        "\n",
        "            elif phase_type == self.DENSE:\n",
        "                phases.append(DensePhase(gene, in_channels, out_channels, idx))\n",
        "\n",
        "            else:\n",
        "                raise NotImplementedError(\"Phase type corresponding to {} not implemented.\".format(phase_type))\n",
        "\n",
        "        self._model = nn.Sequential(*self.build_layers(phases))\n",
        "\n",
        "    def adjust_types(self, genome, phase_types):\n",
        "        \"\"\"\n",
        "        Get only the phases that are active.\n",
        "        Similar to ResidualDecoder.get_effective_genome but we need to consider phases too.\n",
        "        :param genome: list, list of ints\n",
        "        :param phase_types: list,\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        effective_types = []\n",
        "\n",
        "        for idx, (gene, phase_type) in enumerate(zip(genome, phase_types)):\n",
        "            if phase_active(gene):\n",
        "                for _ in range(self._repeats[idx]):\n",
        "                    effective_types.append(*phase_type)\n",
        "\n",
        "        return effective_types\n",
        "\n",
        "    def get_model(self):\n",
        "        return self._model\n",
        "\n",
        "\n",
        "class DenseGenomeDecoder(ChannelBasedDecoder):\n",
        "    \"\"\"\n",
        "    Genetic CNN genome decoder with residual bit.\n",
        "    \"\"\"\n",
        "    def __init__(self, list_genome, channels, repeats=None):\n",
        "        \"\"\"\n",
        "        Constructor.\n",
        "        :param list_genome: list, genome describing the connections in a network.\n",
        "        :param channels: list, list of tuples describing the channel size changes.\n",
        "        :param repeats: None | list, list of integers describing how many times to repeat each phase.\n",
        "        \"\"\"\n",
        "        super().__init__(list_genome, channels, repeats=repeats)\n",
        "\n",
        "        if self._model is not None:\n",
        "            return  # Exit if the parent constructor set the model.\n",
        "\n",
        "        # Build up the appropriate number of phases.\n",
        "        phases = []\n",
        "        for idx, (gene, (in_channels, out_channels)) in enumerate(zip(self._genome, self._channels)):\n",
        "            phases.append(DensePhase(gene, in_channels, out_channels, idx))\n",
        "\n",
        "        self._model = nn.Sequential(*self.build_layers(phases))\n",
        "\n",
        "    @staticmethod\n",
        "    def get_effective_genome(genome):\n",
        "        \"\"\"\n",
        "        Get only the parts of the genome that are active.\n",
        "        :param genome: list, represents the genome\n",
        "        :return: list\n",
        "        \"\"\"\n",
        "        return [gene for gene in genome if phase_active(gene)]\n",
        "\n",
        "    def get_model(self):\n",
        "        \"\"\"\n",
        "        :return: nn.Module\n",
        "        \"\"\"\n",
        "        return self._model\n",
        "\n",
        "\n",
        "class DensePhase(nn.Module):\n",
        "    \"\"\"\n",
        "    Phase with nodes that operates like DenseNet's bottle necking and growth rate scheme.\n",
        "    Refer to: https://arxiv.org/pdf/1608.06993.pdf\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, gene, in_channels, out_channels, idx):\n",
        "        \"\"\"\n",
        "        Constructor.\n",
        "        :param gene: list, element of genome describing connections in this phase.\n",
        "        :param in_channels: int, number of input channels.\n",
        "        :param out_channels: int, number of output channels.\n",
        "        :param idx: int, index in the network.\n",
        "        \"\"\"\n",
        "        super(DensePhase, self).__init__()\n",
        "\n",
        "        self.in_channel_flag = in_channels != out_channels  # Flag to tell us if we need to increase channel size.\n",
        "        self.out_channel_flag = out_channels != DenseNode.t\n",
        "        self.first_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1 if idx != 0 else 3, stride=1, bias=False)\n",
        "        self.dependency_graph = ResidualPhase.build_dependency_graph(gene)\n",
        "\n",
        "        channel_adjustment = 0\n",
        "\n",
        "        for dep in self.dependency_graph[len(gene) + 1]:\n",
        "            if dep == 0:\n",
        "                channel_adjustment += out_channels\n",
        "\n",
        "            else:\n",
        "                channel_adjustment += DenseNode.t\n",
        "\n",
        "        self.last_conv = nn.Conv2d(channel_adjustment, out_channels, kernel_size=1, stride=1, bias=False)\n",
        "\n",
        "        nodes = []\n",
        "        for i in range(len(gene)):\n",
        "            if len(self.dependency_graph[i + 1]) > 0:\n",
        "                channels = self.compute_channels(self.dependency_graph[i + 1], out_channels)\n",
        "                nodes.append(DenseNode(channels))\n",
        "\n",
        "            else:\n",
        "                nodes.append(None)\n",
        "\n",
        "        self.nodes = nn.ModuleList(nodes)\n",
        "        self.out = nn.Sequential(\n",
        "            self.last_conv,\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_channels(dependency, out_channels):\n",
        "        \"\"\"\n",
        "        Compute the number of channels incoming to a node.\n",
        "        :param dependency: list, nodes that a particular node gets input from.\n",
        "        :param out_channels: int, desired number of output channels from the phase.\n",
        "        :return: int\n",
        "        \"\"\"\n",
        "        channels = 0\n",
        "        for d in dependency:\n",
        "            if d == 0:\n",
        "                channels += out_channels\n",
        "\n",
        "            else:\n",
        "                channels += DenseNode.t\n",
        "\n",
        "        return channels\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.in_channel_flag:\n",
        "            x = self.first_conv(x)\n",
        "\n",
        "        outputs = [x]\n",
        "\n",
        "        for i in range(1, len(self.nodes) + 1):\n",
        "            if not self.dependency_graph[i]:  # Empty dependencies, no output to give.\n",
        "                outputs.append(None)\n",
        "\n",
        "            else:\n",
        "                # Call the node on the depthwise concatenation of its inputs.\n",
        "                outputs.append(self.nodes[i - 1](torch.cat([outputs[j] for j in self.dependency_graph[i]], dim=1)))\n",
        "\n",
        "        if self.out_channel_flag and 0 in self.dependency_graph[len(self.nodes) + 1]:\n",
        "            # Get the last nodes in the phase and change their channels to match the desired output.\n",
        "            non_zero_dep = [dep for dep in self.dependency_graph[len(self.nodes) + 1] if dep != 0]\n",
        "\n",
        "            return self.out(torch.cat([outputs[i] for i in non_zero_dep] + [outputs[0]], dim=1))\n",
        "\n",
        "        if self.out_channel_flag:\n",
        "            # Same as above, we just don't worry about the 0th node.\n",
        "            return self.out(torch.cat([outputs[i] for i in self.dependency_graph[len(self.nodes) + 1]], dim=1))\n",
        "\n",
        "        return self.out(torch.cat([outputs[i] for i in self.dependency_graph[len(self.nodes) + 1]]))\n",
        "\n",
        "\n",
        "class DenseNode(nn.Module):\n",
        "    \"\"\"\n",
        "    Node that operates like DenseNet layers.\n",
        "    Refer to: https://arxiv.org/pdf/1608.06993.pdf\n",
        "    \"\"\"\n",
        "    t = 64  # Growth rate fixed at 32 (a hyperparameter, although fixed in paper)\n",
        "    k = 4  # Growth rate multiplier fixed at 4 (not a hyperparameter, this is from the definition of the dense layer).\n",
        "\n",
        "    def __init__(self, in_channels):\n",
        "        \"\"\"\n",
        "        Constructor.\n",
        "        Only needs number of input channels, everything else is automatic from growth rate and DenseNet specs.\n",
        "        :param in_channels: int, input channels.\n",
        "        \"\"\"\n",
        "        super(DenseNode, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels, self.t * self.k, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(self.t * self.k),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.t * self.k, self.t, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "def phase_active(gene):\n",
        "    \"\"\"\n",
        "    Determine if a phase is active.\n",
        "    :param gene: list, gene describing a phase.\n",
        "    :return: bool, true if active.\n",
        "    \"\"\"\n",
        "    # The residual bit is not relevant in if a phase is active, so we ignore it, i.e. gene[:-1].\n",
        "    return sum([sum(t) for t in gene[:-1]]) != 0\n",
        "\n",
        "\n",
        "class GCNNGenomeDecoder(Decoder):\n",
        "    \"\"\"\n",
        "    Original genetic CNN genome from: https://arxiv.org/abs/1703.01513\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, list_genome):\n",
        "        super().__init__(list_genome)\n",
        "        pass\n",
        "\n",
        "    def get_model(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class DONGenomeDecoder(Decoder):\n",
        "    \"\"\"\n",
        "    'Double Or Nothing genome' decoder.\n",
        "    DON refers to the channel size strategy which either doubles or does before a phase.\n",
        "    Also defines residual as ResidualGenome does.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, list_genome):\n",
        "        super().__init__(list_genome)\n",
        "        pass\n",
        "\n",
        "    def get_model(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class Identity(nn.Module):\n",
        "    \"\"\"\n",
        "    Adding an identity allows us to keep things general in certain places.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Identity, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x"
      ],
      "metadata": {
        "id": "gFJllP4549mD"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_decoder(decoder_str, genome, channels, repeats=None):\n",
        "    \"\"\"\n",
        "    Construct the appropriate decoder.\n",
        "    :param decoder_str: string, refers to what genome scheme we're using.\n",
        "    :param genome: list, list of genomes.\n",
        "    :param channels: list, list of channel sizes.\n",
        "    :param repeats: None | list, how many times to repeat each phase.\n",
        "    :return: evolution.ChannelBasedDecoder\n",
        "    \"\"\"\n",
        "    if decoder_str == \"residual\":\n",
        "        return ResidualGenomeDecoder(genome, channels, repeats=repeats)\n",
        "\n",
        "    if decoder_str == \"swapped-residual\":\n",
        "        return ResidualGenomeDecoder(genome, channels, preact=True, repeats=repeats)\n",
        "\n",
        "    if decoder_str == \"dense\":\n",
        "        return DenseGenomeDecoder(genome, channels, repeats=repeats)\n",
        "\n",
        "    if decoder_str == \"variable\":\n",
        "        return VariableGenomeDecoder(genome, channels, repeats=repeats)\n",
        "\n",
        "    raise NotImplementedError(\"Decoder {} not implemented.\".format(decoder_str))"
      ],
      "metadata": {
        "id": "cgaBDJiC5Aca"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EvoNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "    Entire network.\n",
        "    Made up of Phases.\n",
        "    \"\"\"\n",
        "    def __init__(self, genome, channels, out_features, data_shape, decoder=\"residual\", repeats=None):\n",
        "        \"\"\"\n",
        "        Network constructor.\n",
        "        :param genome: depends on decoder scheme, for most this is a list.\n",
        "        :param channels: list of desired channel tuples.\n",
        "        :param out_features: number of output features.\n",
        "        :param decoder: string, what kind of decoding scheme to use.\n",
        "        \"\"\"\n",
        "        super(EvoNetwork, self).__init__()\n",
        "\n",
        "        assert len(channels) == len(genome), \"Need to supply as many channel tuples as genes.\"\n",
        "        if repeats is not None:\n",
        "            assert len(repeats) == len(genome), \"Need to supply repetition information for each phase.\"\n",
        "\n",
        "        self.model = get_decoder(decoder, genome, channels, repeats).get_model()\n",
        "\n",
        "        #\n",
        "        # After the evolved part of the network, we would like to do global average pooling and a linear layer.\n",
        "        # However, we don't know the output size so we do some forward passes and observe the output sizes.\n",
        "        #\n",
        "\n",
        "        out = self.model(torch.autograd.Variable(torch.zeros(1, channels[0][0], *data_shape)))\n",
        "        shape = out.data.shape\n",
        "\n",
        "        self.gap = nn.AvgPool2d(kernel_size=(shape[-2], shape[-1]), stride=1)\n",
        "\n",
        "        shape = self.gap(out).data.shape\n",
        "\n",
        "        self.linear = nn.Linear(shape[1] * shape[2] * shape[3], out_features)\n",
        "\n",
        "        # We accumulated some unwanted gradient information data with those forward passes.\n",
        "        self.model.zero_grad()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward propagation.\n",
        "        :param x: Variable, input to network.\n",
        "        :return: Variable.\n",
        "        \"\"\"\n",
        "        x = self.gap(self.model(x))\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        return self.linear(x), None\n"
      ],
      "metadata": {
        "id": "OJSSssxf5CLF"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Cutout(object):\n",
        "    def __init__(self, length):\n",
        "        self.length = length\n",
        "\n",
        "    def __call__(self, img):\n",
        "        h, w = img.size(1), img.size(2)\n",
        "        mask = np.ones((h, w), np.float32)\n",
        "        y = np.random.randint(h)\n",
        "        x = np.random.randint(w)\n",
        "\n",
        "        y1 = np.clip(y - self.length // 2, 0, h)\n",
        "        y2 = np.clip(y + self.length // 2, 0, h)\n",
        "        x1 = np.clip(x - self.length // 2, 0, w)\n",
        "        x2 = np.clip(x + self.length // 2, 0, w)\n",
        "\n",
        "        mask[y1: y2, x1: x2] = 0.\n",
        "        mask = torch.from_numpy(mask)\n",
        "        mask = mask.expand_as(img)\n",
        "        img *= mask\n",
        "        return img"
      ],
      "metadata": {
        "id": "360Wser65EOn"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_integrity(fpath, md5):\n",
        "    if not os.path.isfile(fpath):\n",
        "        return False\n",
        "    md5o = hashlib.md5()\n",
        "    with open(fpath, 'rb') as f:\n",
        "        # read in 1MB chunks\n",
        "        for chunk in iter(lambda: f.read(1024 * 1024), b''):\n",
        "            md5o.update(chunk)\n",
        "    md5c = md5o.hexdigest()\n",
        "    if md5c != md5:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def download_url(url, root, filename, md5):\n",
        "    from six.moves import urllib\n",
        "\n",
        "    root = os.path.expanduser(root)\n",
        "    fpath = os.path.join(root, filename)\n",
        "\n",
        "    try:\n",
        "        os.makedirs(root)\n",
        "    except OSError as e:\n",
        "        if e.errno == errno.EEXIST:\n",
        "            pass\n",
        "        else:\n",
        "            raise\n",
        "\n",
        "    # downloads file\n",
        "    if os.path.isfile(fpath) and check_integrity(fpath, md5):\n",
        "        print('Using downloaded and verified file: ' + fpath)\n",
        "    else:\n",
        "        try:\n",
        "            print('Downloading ' + url + ' to ' + fpath)\n",
        "            urllib.request.urlretrieve(url, fpath)\n",
        "        except:\n",
        "            if url[:5] == 'https':\n",
        "                url = url.replace('https:', 'http:')\n",
        "                print('Failed download. Trying https -> http instead.'\n",
        "                      ' Downloading ' + url + ' to ' + fpath)\n",
        "                urllib.request.urlretrieve(url, fpath)\n",
        "\n",
        "\n",
        "class CIFAR10(data.Dataset):\n",
        "    \"\"\"`CIFAR10 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
        "    Args:\n",
        "        root (string): Root directory of dataset where directory\n",
        "            ``cifar-10-batches-py`` exists or will be saved to if download is set to True.\n",
        "        train (bool, optional): If True, creates dataset from training set, otherwise\n",
        "            creates from test set.\n",
        "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
        "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
        "        target_transform (callable, optional): A function/transform that takes in the\n",
        "            target and transforms it.\n",
        "        download (bool, optional): If true, downloads the dataset from the internet and\n",
        "            puts it in root directory. If dataset is already downloaded, it is not\n",
        "            downloaded again.\n",
        "    \"\"\"\n",
        "    base_folder = 'cifar-10-batches-py'\n",
        "    url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
        "    filename = \"cifar-10-python.tar.gz\"\n",
        "    tgz_md5 = 'c58f30108f718f92721af3b95e74349a'\n",
        "    train_list = [\n",
        "        ['data_batch_1', 'c99cafc152244af753f735de768cd75f'],\n",
        "        ['data_batch_2', 'd4bba439e000b95fd0a9bffe97cbabec'],\n",
        "        ['data_batch_3', '54ebc095f3ab1f0389bbae665268c751'],\n",
        "        ['data_batch_4', '634d18415352ddfa80567beed471001a'],\n",
        "    ]\n",
        "\n",
        "    test_list = [\n",
        "        ['data_batch_5', '482c414d41f54cd18b22e5b47cb7c3cb'],\n",
        "    ]\n",
        "\n",
        "    # original cifar 10 test set\n",
        "    # test_list = [\n",
        "    #     ['test_batch', '40351d587109b95175f43aff81a1287e'],\n",
        "    # ]\n",
        "\n",
        "    def __init__(self, root, train=True,\n",
        "                 transform=None, target_transform=None,\n",
        "                 download=False):\n",
        "        self.root = os.path.expanduser(root)\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.train = train  # training set or test set\n",
        "\n",
        "        if download:\n",
        "            self.download()\n",
        "\n",
        "        if not self._check_integrity():\n",
        "            raise RuntimeError('Dataset not found or corrupted.' +\n",
        "                               ' You can use download=True to download it')\n",
        "\n",
        "        # now load the picked numpy arrays\n",
        "        if self.train:\n",
        "            self.train_data = []\n",
        "            self.train_labels = []\n",
        "            for fentry in self.train_list:\n",
        "                f = fentry[0]\n",
        "                file = os.path.join(self.root, self.base_folder, f)\n",
        "                fo = open(file, 'rb')\n",
        "                if sys.version_info[0] == 2:\n",
        "                    entry = pickle.load(fo)\n",
        "                else:\n",
        "                    entry = pickle.load(fo, encoding='latin1')\n",
        "                self.train_data.append(entry['data'])\n",
        "                if 'labels' in entry:\n",
        "                    self.train_labels += entry['labels']\n",
        "                else:\n",
        "                    self.train_labels += entry['fine_labels']\n",
        "                fo.close()\n",
        "\n",
        "            self.train_data = np.concatenate(self.train_data)\n",
        "            self.train_data = self.train_data.reshape((40000, 3, 32, 32))\n",
        "            self.train_data = self.train_data.transpose((0, 2, 3, 1))  # convert to HWC\n",
        "        else:\n",
        "            f = self.test_list[0][0]\n",
        "            file = os.path.join(self.root, self.base_folder, f)\n",
        "            fo = open(file, 'rb')\n",
        "            if sys.version_info[0] == 2:\n",
        "                entry = pickle.load(fo)\n",
        "            else:\n",
        "                entry = pickle.load(fo, encoding='latin1')\n",
        "            self.test_data = entry['data']\n",
        "            if 'labels' in entry:\n",
        "                self.test_labels = entry['labels']\n",
        "            else:\n",
        "                self.test_labels = entry['fine_labels']\n",
        "            fo.close()\n",
        "            self.test_data = self.test_data.reshape((10000, 3, 32, 32))\n",
        "            self.test_data = self.test_data.transpose((0, 2, 3, 1))  # convert to HWC\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index (int): Index\n",
        "        Returns:\n",
        "            tuple: (image, target) where target is index of the target class.\n",
        "        \"\"\"\n",
        "        if self.train:\n",
        "            img, target = self.train_data[index], self.train_labels[index]\n",
        "        else:\n",
        "            img, target = self.test_data[index], self.test_labels[index]\n",
        "\n",
        "        # doing this so that it is consistent with all other datasets\n",
        "        # to return a PIL Image\n",
        "        img = Image.fromarray(img)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.train:\n",
        "            return len(self.train_data)\n",
        "        else:\n",
        "            return len(self.test_data)\n",
        "\n",
        "    def _check_integrity(self):\n",
        "        root = self.root\n",
        "        for fentry in (self.train_list + self.test_list):\n",
        "            filename, md5 = fentry[0], fentry[1]\n",
        "            fpath = os.path.join(root, self.base_folder, filename)\n",
        "            if not check_integrity(fpath, md5):\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    def download(self):\n",
        "        import tarfile\n",
        "\n",
        "        if self._check_integrity():\n",
        "            # print('Files already downloaded and verified')\n",
        "            return\n",
        "\n",
        "        root = self.root\n",
        "        download_url(self.url, root, self.filename, self.tgz_md5)\n",
        "\n",
        "        # extract file\n",
        "        cwd = os.getcwd()\n",
        "        tar = tarfile.open(os.path.join(root, self.filename), \"r:gz\")\n",
        "        os.chdir(root)\n",
        "        tar.extractall()\n",
        "        tar.close()\n",
        "        os.chdir(cwd)\n",
        "\n",
        "    def __repr__(self):\n",
        "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
        "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
        "        tmp = 'train' if self.train is True else 'test'\n",
        "        fmt_str += '    Split: {}\\n'.format(tmp)\n",
        "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
        "        tmp = '    Transforms (if any): '\n",
        "        fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
        "        tmp = '    Target Transforms (if any): '\n",
        "        fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
        "        return fmt_str"
      ],
      "metadata": {
        "id": "3dJ2VM9y5JnU"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_flops_mask_variable_or_reset(module):\n",
        "    if is_supported_instance(module):\n",
        "        module.__mask__ = None"
      ],
      "metadata": {
        "id": "GfmEN8mz5NBQ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flops_to_string(flops):\n",
        "    if flops // 10**9 > 0:\n",
        "        return str(round(flops / 10.**9, 2)) + 'GMac'\n",
        "    elif flops // 10**6 > 0:\n",
        "        return str(round(flops / 10.**6, 2)) + 'MMac'\n",
        "    elif flops // 10**3 > 0:\n",
        "        return str(round(flops / 10.**3, 2)) + 'KMac'\n",
        "    return str(flops) + 'Mac'\n",
        "\n",
        "\n",
        "def get_model_parameters_number(model, as_string=True):\n",
        "    params_num = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    if not as_string:\n",
        "        return params_num\n",
        "\n",
        "    if params_num // 10 ** 6 > 0:\n",
        "        return str(round(params_num / 10 ** 6, 2)) + 'M'\n",
        "    elif params_num // 10 ** 3:\n",
        "        return str(round(params_num / 10 ** 3, 2)) + 'k'\n",
        "\n",
        "    return str(params_num)\n",
        "\n",
        "\n",
        "def add_flops_counting_methods(net_main_module):\n",
        "    # adding additional methods to the existing module object,\n",
        "    # this is done this way so that each function has access to self object\n",
        "    net_main_module.start_flops_count = start_flops_count.__get__(net_main_module)\n",
        "    net_main_module.stop_flops_count = stop_flops_count.__get__(net_main_module)\n",
        "    net_main_module.reset_flops_count = reset_flops_count.__get__(net_main_module)\n",
        "    net_main_module.compute_average_flops_cost = compute_average_flops_cost.__get__(net_main_module)\n",
        "\n",
        "    net_main_module.reset_flops_count()\n",
        "\n",
        "    # Adding variables necessary for masked flops computation\n",
        "    net_main_module.apply(add_flops_mask_variable_or_reset)\n",
        "\n",
        "    return net_main_module\n",
        "\n",
        "\n",
        "def compute_average_flops_cost(self):\n",
        "    \"\"\"\n",
        "    A method that will be available after add_flops_counting_methods() is called\n",
        "    on a desired net object.\n",
        "    Returns current mean flops consumption per image.\n",
        "    \"\"\"\n",
        "\n",
        "    batches_count = self.__batch_counter__\n",
        "    flops_sum = 0\n",
        "    for module in self.modules():\n",
        "        if is_supported_instance(module):\n",
        "            flops_sum += module.__flops__\n",
        "\n",
        "    return flops_sum / batches_count\n",
        "\n",
        "\n",
        "def start_flops_count(self):\n",
        "    \"\"\"\n",
        "    A method that will be available after add_flops_counting_methods() is called\n",
        "    on a desired net object.\n",
        "    Activates the computation of mean flops consumption per image.\n",
        "    Call it before you run the network.\n",
        "    \"\"\"\n",
        "    add_batch_counter_hook_function(self)\n",
        "    self.apply(add_flops_counter_hook_function)\n",
        "\n",
        "\n",
        "def stop_flops_count(self):\n",
        "    \"\"\"\n",
        "    A method that will be available after add_flops_counting_methods() is called\n",
        "    on a desired net object.\n",
        "    Stops computing the mean flops consumption per image.\n",
        "    Call whenever you want to pause the computation.\n",
        "    \"\"\"\n",
        "    remove_batch_counter_hook_function(self)\n",
        "    self.apply(remove_flops_counter_hook_function)\n",
        "\n",
        "\n",
        "def reset_flops_count(self):\n",
        "    \"\"\"\n",
        "    A method that will be available after add_flops_counting_methods() is called\n",
        "    on a desired net object.\n",
        "    Resets statistics computed so far.\n",
        "    \"\"\"\n",
        "    add_batch_counter_variables_or_reset(self)\n",
        "    self.apply(add_flops_counter_variable_or_reset)\n",
        "\n",
        "\n",
        "def add_flops_mask(module, mask):\n",
        "    def add_flops_mask_func(module):\n",
        "        if isinstance(module, torch.nn.Conv2d):\n",
        "            module.__mask__ = mask\n",
        "    module.apply(add_flops_mask_func)\n",
        "\n",
        "\n",
        "def remove_flops_mask(module):\n",
        "    module.apply(add_flops_mask_variable_or_reset)\n",
        "\n",
        "\n",
        "# ---- Internal functions\n",
        "def is_supported_instance(module):\n",
        "    if isinstance(module, (torch.nn.Conv2d, torch.nn.ReLU, torch.nn.PReLU, torch.nn.ELU, \\\n",
        "                           torch.nn.LeakyReLU, torch.nn.ReLU6, torch.nn.Linear, \\\n",
        "                           torch.nn.MaxPool2d, torch.nn.AvgPool2d, torch.nn.BatchNorm2d, \\\n",
        "                           torch.nn.Upsample, nn.AdaptiveMaxPool2d, nn.AdaptiveAvgPool2d)):\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "\n",
        "def empty_flops_counter_hook(module, input, output):\n",
        "    module.__flops__ += 0\n",
        "\n",
        "\n",
        "def upsample_flops_counter_hook(module, input, output):\n",
        "    output_size = output[0]\n",
        "    batch_size = output_size.shape[0]\n",
        "    output_elements_count = batch_size\n",
        "    for val in output_size.shape[1:]:\n",
        "        output_elements_count *= val\n",
        "    module.__flops__ += output_elements_count\n",
        "\n",
        "\n",
        "def relu_flops_counter_hook(module, input, output):\n",
        "    active_elements_count = output.numel()\n",
        "    module.__flops__ += active_elements_count\n",
        "\n",
        "\n",
        "def linear_flops_counter_hook(module, input, output):\n",
        "    input = input[0]\n",
        "    batch_size = input.shape[0]\n",
        "    module.__flops__ += batch_size * input.shape[1] * output.shape[1]\n",
        "\n",
        "\n",
        "def pool_flops_counter_hook(module, input, output):\n",
        "    input = input[0]\n",
        "    module.__flops__ += np.prod(input.shape)\n",
        "\n",
        "def bn_flops_counter_hook(module, input, output):\n",
        "    module.affine\n",
        "    input = input[0]\n",
        "\n",
        "    batch_flops = np.prod(input.shape)\n",
        "    if module.affine:\n",
        "        batch_flops *= 2\n",
        "    module.__flops__ += batch_flops\n",
        "\n",
        "def conv_flops_counter_hook(conv_module, input, output):\n",
        "    # Can have multiple inputs, getting the first one\n",
        "    input = input[0]\n",
        "\n",
        "    batch_size = input.shape[0]\n",
        "    output_height, output_width = output.shape[2:]\n",
        "\n",
        "    kernel_height, kernel_width = conv_module.kernel_size\n",
        "    in_channels = conv_module.in_channels\n",
        "    out_channels = conv_module.out_channels\n",
        "    groups = conv_module.groups\n",
        "\n",
        "    filters_per_channel = out_channels // groups\n",
        "    conv_per_position_flops = kernel_height * kernel_width * in_channels * filters_per_channel\n",
        "\n",
        "    active_elements_count = batch_size * output_height * output_width\n",
        "\n",
        "    if conv_module.__mask__ is not None:\n",
        "        # (b, 1, h, w)\n",
        "        flops_mask = conv_module.__mask__.expand(batch_size, 1, output_height, output_width)\n",
        "        active_elements_count = flops_mask.sum()\n",
        "\n",
        "    overall_conv_flops = conv_per_position_flops * active_elements_count\n",
        "\n",
        "    bias_flops = 0\n",
        "\n",
        "    if conv_module.bias is not None:\n",
        "\n",
        "        bias_flops = out_channels * active_elements_count\n",
        "\n",
        "    overall_flops = overall_conv_flops + bias_flops\n",
        "\n",
        "    conv_module.__flops__ += overall_flops\n",
        "\n",
        "\n",
        "def batch_counter_hook(module, input, output):\n",
        "    # Can have multiple inputs, getting the first one\n",
        "    input = input[0]\n",
        "    batch_size = input.shape[0]\n",
        "    module.__batch_counter__ += batch_size\n",
        "\n",
        "\n",
        "def add_batch_counter_variables_or_reset(module):\n",
        "\n",
        "    module.__batch_counter__ = 0\n",
        "\n",
        "\n",
        "def add_batch_counter_hook_function(module):\n",
        "    if hasattr(module, '__batch_counter_handle__'):\n",
        "        return\n",
        "\n",
        "    handle = module.register_forward_hook(batch_counter_hook)\n",
        "    module.__batch_counter_handle__ = handle\n",
        "\n",
        "\n",
        "def remove_batch_counter_hook_function(module):\n",
        "    if hasattr(module, '__batch_counter_handle__'):\n",
        "        module.__batch_counter_handle__.remove()\n",
        "        del module.__batch_counter_handle__\n",
        "\n",
        "\n",
        "def add_flops_counter_variable_or_reset(module):\n",
        "    if is_supported_instance(module):\n",
        "        module.__flops__ = 0\n",
        "\n",
        "\n",
        "def add_flops_counter_hook_function(module):\n",
        "    if is_supported_instance(module):\n",
        "        if hasattr(module, '__flops_handle__'):\n",
        "            return\n",
        "\n",
        "        if isinstance(module, torch.nn.Conv2d):\n",
        "            handle = module.register_forward_hook(conv_flops_counter_hook)\n",
        "        elif isinstance(module, (torch.nn.ReLU, torch.nn.PReLU, torch.nn.ELU, \\\n",
        "                                 torch.nn.LeakyReLU, torch.nn.ReLU6)):\n",
        "            handle = module.register_forward_hook(relu_flops_counter_hook)\n",
        "        elif isinstance(module, torch.nn.Linear):\n",
        "            handle = module.register_forward_hook(linear_flops_counter_hook)\n",
        "        elif isinstance(module, (torch.nn.AvgPool2d, torch.nn.MaxPool2d, nn.AdaptiveMaxPool2d, \\\n",
        "                                 nn.AdaptiveAvgPool2d)):\n",
        "            handle = module.register_forward_hook(pool_flops_counter_hook)\n",
        "        elif isinstance(module, torch.nn.BatchNorm2d):\n",
        "            handle = module.register_forward_hook(bn_flops_counter_hook)\n",
        "        elif isinstance(module, torch.nn.Upsample):\n",
        "            handle = module.register_forward_hook(upsample_flops_counter_hook)\n",
        "        else:\n",
        "            handle = module.register_forward_hook(empty_flops_counter_hook)\n",
        "        module.__flops_handle__ = handle\n",
        "\n",
        "\n",
        "def remove_flops_counter_hook_function(module):\n",
        "    if is_supported_instance(module):\n",
        "        if hasattr(module, '__flops_handle__'):\n",
        "            module.__flops_handle__.remove()\n",
        "            del module.__flops_handle__\n",
        "# --- Masked flops counting\n"
      ],
      "metadata": {
        "id": "Z3ccuvoc5OgQ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_search(genome, epochs, search_space='macro',\n",
        "         save='Design_1', expr_root='search', seed=0, gpu=0, init_channels=24,\n",
        "         layers=11, auxiliary=False, cutout=False, drop_path_prob=0.0):\n",
        "\n",
        "    # ---- train logger ----------------- #\n",
        "    save_pth = os.path.join(expr_root, '{}'.format(save))\n",
        "    create_exp_dir(save_pth)\n",
        "    log_format = '%(asctime)s %(message)s'\n",
        "    logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
        "                        format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
        "    # fh = logging.FileHandler(os.path.join(save_pth, 'log.txt'))\n",
        "    # fh.setFormatter(logging.Formatter(log_format))\n",
        "    # logging.getLogger().addHandler(fh)\n",
        "\n",
        "    # ---- parameter values setting ----- #\n",
        "    CIFAR_CLASSES = 10\n",
        "    learning_rate = 0.025\n",
        "    momentum = 0.9\n",
        "    weight_decay = 3e-4\n",
        "    data_root = '../data'\n",
        "    batch_size = 128\n",
        "    cutout_length = 16\n",
        "    auxiliary_weight = 0.4\n",
        "    grad_clip = 5\n",
        "    report_freq = 50\n",
        "    train_params = {\n",
        "        'auxiliary': auxiliary,\n",
        "        'auxiliary_weight': auxiliary_weight,\n",
        "        'grad_clip': grad_clip,\n",
        "        'report_freq': report_freq,\n",
        "    }\n",
        "\n",
        "    if search_space == 'macro':\n",
        "        genotype = decode(genome)\n",
        "        channels = [(3, init_channels),\n",
        "                    (init_channels, 2*init_channels),\n",
        "                    (2*init_channels, 4*init_channels)]\n",
        "        model = EvoNetwork(genotype, channels, CIFAR_CLASSES, (32, 32), decoder='residual')\n",
        "    else:\n",
        "        raise NameError('Unknown search space type')\n",
        "\n",
        "    # logging.info(\"Genome = %s\", genome)\n",
        "    logging.info(\"Architecture = %s\", genotype)\n",
        "\n",
        "    torch.cuda.set_device(gpu)\n",
        "    cudnn.benchmark = True\n",
        "    torch.manual_seed(seed)\n",
        "    cudnn.enabled = True\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "    n_params = (np.sum(np.prod(v.size()) for v in filter(lambda p: p.requires_grad, model.parameters())) / 1e6)\n",
        "    model = model.to(device)\n",
        "\n",
        "    logging.info(\"param size = %fMB\", n_params)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    criterion = criterion.cuda()\n",
        "\n",
        "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    optimizer = torch.optim.SGD(\n",
        "        parameters,\n",
        "        learning_rate,\n",
        "        momentum=momentum,\n",
        "        weight_decay=weight_decay\n",
        "    )\n",
        "\n",
        "    CIFAR_MEAN = [0.49139968, 0.48215827, 0.44653124]\n",
        "    CIFAR_STD = [0.24703233, 0.24348505, 0.26158768]\n",
        "\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    if cutout:\n",
        "        train_transform.transforms.append(Cutout(cutout_length))\n",
        "\n",
        "    train_transform.transforms.append(transforms.Normalize(CIFAR_MEAN, CIFAR_STD))\n",
        "\n",
        "    valid_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(CIFAR_MEAN, CIFAR_STD),\n",
        "    ])\n",
        "\n",
        "    train_data = CIFAR10(root=data_root, train=True, download=True, transform=train_transform)\n",
        "    valid_data = CIFAR10(root=data_root, train=False, download=True, transform=valid_transform)\n",
        "\n",
        "    # num_train = len(train_data)\n",
        "    # indices = list(range(num_train))\n",
        "    # split = int(np.floor(train_portion * num_train))\n",
        "\n",
        "    train_queue = torch.utils.data.DataLoader(\n",
        "        train_data, batch_size=batch_size,\n",
        "        # sampler=torch.utils.data.sampler.SubsetRandomSampler(indices[:split]),\n",
        "        pin_memory=True, num_workers=2)\n",
        "\n",
        "    valid_queue = torch.utils.data.DataLoader(\n",
        "        valid_data, batch_size=batch_size,\n",
        "        # sampler=torch.utils.data.sampler.SubsetRandomSampler(indices[split:num_train]),\n",
        "        pin_memory=True, num_workers=2)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, int(epochs))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        scheduler.step()\n",
        "        logging.info('epoch %d lr %e', epoch, scheduler.get_lr()[0])\n",
        "        model.droprate = drop_path_prob * epoch / epochs\n",
        "\n",
        "        train_acc, train_obj = train(train_queue, model, criterion, optimizer, train_params)\n",
        "        logging.info('train_acc %f', train_acc)\n",
        "\n",
        "    valid_acc, valid_obj = infer(valid_queue, model, criterion)\n",
        "    logging.info('valid_acc %f', valid_acc)\n",
        "\n",
        "    # calculate for flops\n",
        "    model = add_flops_counting_methods(model)\n",
        "    model.eval()\n",
        "    model.start_flops_count()\n",
        "    random_data = torch.randn(1, 3, 32, 32)\n",
        "    model(torch.autograd.Variable(random_data).to(device))\n",
        "    n_flops = np.round(model.compute_average_flops_cost() / 1e6, 4)\n",
        "    logging.info('flops = %f', n_flops)\n",
        "\n",
        "    # save to file\n",
        "    # os.remove(os.path.join(save_pth, 'log.txt'))\n",
        "    with open(os.path.join(save_pth, 'log.txt'), \"w\") as file:\n",
        "        file.write(\"Genome = {}\\n\".format(genome))\n",
        "        file.write(\"Architecture = {}\\n\".format(genotype))\n",
        "        file.write(\"param size = {}MB\\n\".format(n_params))\n",
        "        file.write(\"flops = {}MB\\n\".format(n_flops))\n",
        "        file.write(\"valid_acc = {}\\n\".format(valid_acc))\n",
        "\n",
        "    # logging.info(\"Architecture = %s\", genotype))\n",
        "\n",
        "    return {\n",
        "        'valid_acc': valid_acc,\n",
        "        'params': n_params,\n",
        "        'flops': n_flops,\n",
        "    }\n",
        "\n",
        "\n",
        "# def train(train_queue, model, criterion, optimizer, params):\n",
        "#     objs = utils.AvgrageMeter()\n",
        "#     top1 = utils.AvgrageMeter()\n",
        "#     top5 = utils.AvgrageMeter()\n",
        "#     model.train()\n",
        "#\n",
        "#     for step, (input, target) in enumerate(train_queue):\n",
        "#         input = Variable(input).cuda()\n",
        "#         target = Variable(target).cuda(async=True)\n",
        "#\n",
        "#         optimizer.zero_grad()\n",
        "#         if params['auxiliary']:\n",
        "#             logits, logits_aux = model(input)\n",
        "#         else:\n",
        "#             logits, _ = model(input)\n",
        "#\n",
        "#         loss = criterion(logits, target)\n",
        "#         if params['auxiliary']:\n",
        "#             loss_aux = criterion(logits_aux, target)\n",
        "#             loss += params['auxiliary_weight'] * loss_aux\n",
        "#         loss.backward()\n",
        "#         nn.utils.clip_grad_norm(model.parameters(), params['grad_clip'])\n",
        "#         optimizer.step()\n",
        "#\n",
        "#         prec1, prec5 = utils.accuracy(logits, target, topk=(1, 5))\n",
        "#         n = input.size(0)\n",
        "#         objs.update(loss.data[0], n)\n",
        "#         top1.update(prec1.data[0], n)\n",
        "#         top5.update(prec5.data[0], n)\n",
        "#\n",
        "#         # if step % params['report_freq'] == 0:\n",
        "#         #     logging.info('train %03d %e %f %f', step, objs.avg, top1.avg, top5.avg)\n",
        "#\n",
        "#     return top1.avg, objs.avg\n",
        "\n",
        "# Training\n",
        "def train(train_queue, net, criterion, optimizer, params):\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for step, (inputs, targets) in enumerate(train_queue):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs, outputs_aux = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        if params['auxiliary']:\n",
        "            loss_aux = criterion(outputs_aux, targets)\n",
        "            loss += params['auxiliary_weight'] * loss_aux\n",
        "\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), params['grad_clip'])\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    #     if step % args.report_freq == 0:\n",
        "    #         logging.info('train %03d %e %f', step, train_loss/total, 100.*correct/total)\n",
        "    #\n",
        "    # logging.info('train acc %f', 100. * correct / total)\n",
        "\n",
        "    return 100.*correct/total, train_loss/total\n",
        "\n",
        "\n",
        "# def infer(valid_queue, model, criterion):\n",
        "#     objs = utils.AvgrageMeter()\n",
        "#     top1 = utils.AvgrageMeter()\n",
        "#     top5 = utils.AvgrageMeter()\n",
        "#     model.eval()\n",
        "#\n",
        "#     for step, (input, target) in enumerate(valid_queue):\n",
        "#         input = Variable(input, volatile=True).cuda()\n",
        "#         target = Variable(target, volatile=True).cuda(async=True)\n",
        "#\n",
        "#         logits, _ = model(input)\n",
        "#\n",
        "#         loss = criterion(logits, target)\n",
        "#\n",
        "#         prec1, prec5 = utils.accuracy(logits, target, topk=(1, 5))\n",
        "#         n = input.size(0)\n",
        "#         objs.update(loss.data[0], n)\n",
        "#         top1.update(prec1.data[0], n)\n",
        "#         top5.update(prec5.data[0], n)\n",
        "#\n",
        "#         # if step % params['report_freq'] == 0:\n",
        "#         #     logging.info('valid %03d %e %f %f', step, objs.avg, top1.avg, top5.avg)\n",
        "#\n",
        "#     return top1.avg, objs.avg\n",
        "\n",
        "\n",
        "def infer(valid_queue, net, criterion):\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for step, (inputs, targets) in enumerate(valid_queue):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs, _ = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            # if step % args.report_freq == 0:\n",
        "            #     logging.info('valid %03d %e %f', step, test_loss/total, 100.*correct/total)\n",
        "\n",
        "    acc = 100.*correct/total\n",
        "    # logging.info('valid acc %f', 100. * correct / total)\n",
        "\n",
        "    return acc, test_loss/total\n"
      ],
      "metadata": {
        "id": "G857DHex5SF2"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert(bit_string, n_phases=3):\n",
        "    # assumes bit_string is a np array\n",
        "    assert bit_string.shape[0] % n_phases == 0\n",
        "    phase_length = bit_string.shape[0] // n_phases\n",
        "    genome = []\n",
        "    for i in range(0, bit_string.shape[0], phase_length):\n",
        "        genome.append((bit_string[i:i+phase_length]).tolist())\n",
        "\n",
        "    return genome"
      ],
      "metadata": {
        "id": "K97uu-pm5T01"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NAS(Problem):\n",
        "    # first define the NAS problem (inherit from pymop)\n",
        "    def __init__(self, search_space='macro', n_var=20, n_obj=1, n_constr=0, lb=None, ub=None,\n",
        "                 init_channels=24, layers=8, epochs=25, save_dir=None):\n",
        "        super().__init__(n_var=n_var, n_obj=n_obj, n_constr=n_constr, type_var=np.int)\n",
        "        self.xl = lb\n",
        "        self.xu = ub\n",
        "        self._search_space = search_space\n",
        "        self._init_channels = init_channels\n",
        "        self._layers = layers\n",
        "        self._epochs = epochs\n",
        "        self._save_dir = save_dir\n",
        "        self._n_evaluated = 0  # keep track of how many architectures are sampled\n",
        "\n",
        "    def _evaluate(self, x, out, *args, **kwargs):\n",
        "\n",
        "        objs = np.full((x.shape[0], self.n_obj), np.nan)\n",
        "        for i in range(x.shape[0]):\n",
        "            arch_id = self._n_evaluated + 1\n",
        "            \n",
        "            logging.info('Network id = {}'.format(arch_id))\n",
        "\n",
        "            # call back-propagation training\n",
        "            if self._search_space == 'macro':\n",
        "                genome = convert(x[i, :])\n",
        "            performance = train_search(genome=genome,\n",
        "                                            search_space=self._search_space,\n",
        "                                            init_channels=self._init_channels,\n",
        "                                            layers=self._layers, cutout=False,\n",
        "                                            epochs=self._epochs,\n",
        "                                            save='arch_{}'.format(arch_id),\n",
        "                                            expr_root=self._save_dir)\n",
        "            # all objectives assume to be MINIMIZED !!!!!\n",
        "            objs[i, 0] = 100 - performance['valid_acc']\n",
        "            objs[i, 1] = performance['flops']\n",
        "\n",
        "            self._n_evaluated += 1\n",
        "\n",
        "        out[\"F\"] = objs\n",
        "        # if your NAS problem has constraints, use the following line to set constraints\n",
        "        # out[\"G\"] = np.column_stack([g1, g2, g3, g4, g5, g6]) in case 6 constraints"
      ],
      "metadata": {
        "id": "FM8wQgLs5Ttl"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_every_generations(algorithm):\n",
        "    # this function will be call every generation\n",
        "    # it has access to the whole algorithm class\n",
        "    gen = algorithm.n_gen\n",
        "    pop_var = algorithm.pop.get(\"X\")\n",
        "    pop_obj = algorithm.pop.get(\"F\")\n",
        "\n",
        "    # report generation info to files\n",
        "    logging.info(\"generation = {}\".format(gen))\n",
        "    logging.info(\"population error: best = {}, mean = {}, \"\n",
        "                 \"median = {}, worst = {}\".format(np.min(pop_obj[:, 0]), np.mean(pop_obj[:, 0]),\n",
        "                                                  np.median(pop_obj[:, 0]), np.max(pop_obj[:, 0])))\n",
        "    logging.info(\"population complexity: best = {}, mean = {}, \"\n",
        "                 \"median = {}, worst = {}\".format(np.min(pop_obj[:, 1]), np.mean(pop_obj[:, 1]),\n",
        "                                                  np.median(pop_obj[:, 1]), np.max(pop_obj[:, 1])))"
      ],
      "metadata": {
        "id": "m5-7LzEX5XCn"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =========================================================================================================\n",
        "# Implementation\n",
        "# based on nsga2 from https://github.com/msu-coinlab/pymoo\n",
        "# =========================================================================================================\n",
        "\n",
        "\n",
        "class NSGANet(GeneticAlgorithm):\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        kwargs['individual'] = Individual(rank=np.inf, crowding=-1)\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.tournament_type = 'comp_by_dom_and_crowding'\n",
        "        self.func_display_attrs = disp_multi_objective\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------------------------------------\n",
        "# Binary Tournament Selection Function\n",
        "# ---------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def binary_tournament(pop, P, algorithm, **kwargs):\n",
        "    if P.shape[1] != 2:\n",
        "        raise ValueError(\"Only implemented for binary tournament!\")\n",
        "\n",
        "    tournament_type = algorithm.tournament_type\n",
        "    S = np.full(P.shape[0], np.nan)\n",
        "\n",
        "    for i in range(P.shape[0]):\n",
        "\n",
        "        a, b = P[i, 0], P[i, 1]\n",
        "\n",
        "        # if at least one solution is infeasible\n",
        "        if pop[a].CV > 0.0 or pop[b].CV > 0.0:\n",
        "            S[i] = compare(a, pop[a].CV, b, pop[b].CV, method='smaller_is_better', return_random_if_equal=True)\n",
        "\n",
        "        # both solutions are feasible\n",
        "        else:\n",
        "\n",
        "            if tournament_type == 'comp_by_dom_and_crowding':\n",
        "                rel = Dominator.get_relation(pop[a].F, pop[b].F)\n",
        "                if rel == 1:\n",
        "                    S[i] = a\n",
        "                elif rel == -1:\n",
        "                    S[i] = b\n",
        "\n",
        "            elif tournament_type == 'comp_by_rank_and_crowding':\n",
        "                S[i] = compare(a, pop[a].rank, b, pop[b].rank,\n",
        "                               method='smaller_is_better')\n",
        "\n",
        "            else:\n",
        "                raise Exception(\"Unknown tournament type.\")\n",
        "\n",
        "            # if rank or domination relation didn't make a decision compare by crowding\n",
        "            if np.isnan(S[i]):\n",
        "                S[i] = compare(a, pop[a].get(\"crowding\"), b, pop[b].get(\"crowding\"),\n",
        "                               method='larger_is_better', return_random_if_equal=True)\n",
        "\n",
        "    return S[:, None].astype(np.int)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------------------------------------\n",
        "# Survival Selection\n",
        "# ---------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "class RankAndCrowdingSurvival(Survival):\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__(True)\n",
        "\n",
        "    def _do(self, pop, n_survive, D=None, **kwargs):\n",
        "\n",
        "        # get the objective space values and objects\n",
        "        F = pop.get(\"F\")\n",
        "\n",
        "        # the final indices of surviving individuals\n",
        "        survivors = []\n",
        "\n",
        "        # do the non-dominated sorting until splitting front\n",
        "        fronts = NonDominatedSorting().do(F, n_stop_if_ranked=n_survive)\n",
        "\n",
        "        for k, front in enumerate(fronts):\n",
        "\n",
        "            # calculate the crowding distance of the front\n",
        "            crowding_of_front = calc_crowding_distance(F[front, :])\n",
        "\n",
        "            # save rank and crowding in the individual class\n",
        "            for j, i in enumerate(front):\n",
        "                pop[i].set(\"rank\", k)\n",
        "                pop[i].set(\"crowding\", crowding_of_front[j])\n",
        "\n",
        "            # current front sorted by crowding distance if splitting\n",
        "            if len(survivors) + len(front) > n_survive:\n",
        "                I = randomized_argsort(crowding_of_front, order='descending', method='numpy')\n",
        "                I = I[:(n_survive - len(survivors))]\n",
        "\n",
        "            # otherwise take the whole front unsorted\n",
        "            else:\n",
        "                I = np.arange(len(front))\n",
        "\n",
        "            # extend the survivors by all or selected individuals\n",
        "            survivors.extend(front[I])\n",
        "\n",
        "        return pop[survivors]\n",
        "\n",
        "\n",
        "def calc_crowding_distance(F):\n",
        "    infinity = 1e+14\n",
        "\n",
        "    n_points = F.shape[0]\n",
        "    n_obj = F.shape[1]\n",
        "\n",
        "    if n_points <= 2:\n",
        "        return np.full(n_points, infinity)\n",
        "    else:\n",
        "\n",
        "        # sort each column and get index\n",
        "        I = np.argsort(F, axis=0, kind='mergesort')\n",
        "\n",
        "        # now really sort the whole array\n",
        "        F = F[I, np.arange(n_obj)]\n",
        "\n",
        "        # get the distance to the last element in sorted list and replace zeros with actual values\n",
        "        dist = np.concatenate([F, np.full((1, n_obj), np.inf)]) \\\n",
        "               - np.concatenate([np.full((1, n_obj), -np.inf), F])\n",
        "\n",
        "        index_dist_is_zero = np.where(dist == 0)\n",
        "\n",
        "        dist_to_last = np.copy(dist)\n",
        "        for i, j in zip(*index_dist_is_zero):\n",
        "            dist_to_last[i, j] = dist_to_last[i - 1, j]\n",
        "\n",
        "        dist_to_next = np.copy(dist)\n",
        "        for i, j in reversed(list(zip(*index_dist_is_zero))):\n",
        "            dist_to_next[i, j] = dist_to_next[i + 1, j]\n",
        "\n",
        "        # normalize all the distances\n",
        "        norm = np.max(F, axis=0) - np.min(F, axis=0)\n",
        "        norm[norm == 0] = np.nan\n",
        "        dist_to_last, dist_to_next = dist_to_last[:-1] / norm, dist_to_next[1:] / norm\n",
        "\n",
        "        # if we divided by zero because all values in one columns are equal replace by none\n",
        "        dist_to_last[np.isnan(dist_to_last)] = 0.0\n",
        "        dist_to_next[np.isnan(dist_to_next)] = 0.0\n",
        "\n",
        "        # sum up the distance to next and last and norm by objectives - also reorder from sorted list\n",
        "        J = np.argsort(I, axis=0)\n",
        "        crowding = np.sum(dist_to_last[J, np.arange(n_obj)] + dist_to_next[J, np.arange(n_obj)], axis=1) / n_obj\n",
        "\n",
        "    # replace infinity with a large number\n",
        "    crowding[np.isinf(crowding)] = infinity\n",
        "\n",
        "    return crowding\n",
        "\n",
        "\n",
        "# =========================================================================================================\n",
        "# Interface\n",
        "# =========================================================================================================\n",
        "\n",
        "\n",
        "def nsganet(\n",
        "        pop_size=100,\n",
        "        sampling=RandomSampling(var_type=np.int),\n",
        "        selection=TournamentSelection(func_comp=binary_tournament),\n",
        "        crossover=PointCrossover(n_points=2),\n",
        "        mutation=PolynomialMutation(eta=3, var_type=np.int),\n",
        "        eliminate_duplicates=True,\n",
        "        n_offsprings=None,\n",
        "        **kwargs):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    pop_size : {pop_size}\n",
        "    sampling : {sampling}\n",
        "    selection : {selection}\n",
        "    crossover : {crossover}\n",
        "    mutation : {mutation}\n",
        "    eliminate_duplicates : {eliminate_duplicates}\n",
        "    n_offsprings : {n_offsprings}\n",
        "    Returns\n",
        "    -------\n",
        "    nsganet : :class:`~pymoo.model.algorithm.Algorithm`\n",
        "        Returns an NSGANet algorithm object.\n",
        "    \"\"\"\n",
        "\n",
        "    return NSGANet(pop_size=pop_size,\n",
        "                   sampling=sampling,\n",
        "                   selection=selection,\n",
        "                   crossover=crossover,\n",
        "                   mutation=mutation,\n",
        "                   survival=RankAndCrowdingSurvival(),\n",
        "                   eliminate_duplicates=eliminate_duplicates,\n",
        "                   n_offsprings=n_offsprings,\n",
        "                   **kwargs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTnp9IPS5fB1",
        "outputId": "cd0e7e00-aa00-44ca-ac43-b13a8af04d6f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-450609aa533b>:164: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  sampling=RandomSampling(var_type=np.int),\n",
            "<ipython-input-46-450609aa533b>:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  mutation=PolynomialMutation(eta=3, var_type=np.int),\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Thân chương trình chính"
      ],
      "metadata": {
        "id": "MOZ2u5Mo5g5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(seed)"
      ],
      "metadata": {
        "id": "KBsLJE0P5j8H"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_var = int(((n_nodes-1)*n_nodes/2 + 1)*3)\n",
        "lb = np.zeros(n_var)\n",
        "ub = np.ones(n_var)"
      ],
      "metadata": {
        "id": "Xq3vDqML5lGL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "problem = NAS(n_var=n_var, search_space=search_space,\n",
        "              n_obj=2, n_constr=0, lb=lb, ub=ub,\n",
        "              init_channels=init_channels, layers=layers,\n",
        "              epochs=epochs, save_dir=save)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aY12sjx5m05",
        "outputId": "90023c27-5791-4282-b209-df6216f1aafb"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-44-302a5ba6fa56>:5: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  super().__init__(n_var=n_var, n_obj=n_obj, n_constr=n_constr, type_var=np.int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "method = nsganet(pop_size=pop_size,\n",
        "                        n_offsprings=n_offspring,\n",
        "                        eliminate_duplicates=True)"
      ],
      "metadata": {
        "id": "8CpGqRtH5oLr"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = minimize(problem,\n",
        "                   method,\n",
        "                   callback=do_every_generations,\n",
        "                   termination=('n_gen', n_gens))"
      ],
      "metadata": {
        "id": "WtoJWGc45p3Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cb2b687-eb9d-4775-f615-46c25eafef46"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_2\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_3\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_4\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_5\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_6\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_7\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_8\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_9\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_10\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_11\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_12\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_13\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_14\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_15\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_16\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_17\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_18\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_19\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_20\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_21\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_22\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_23\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_24\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_25\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_26\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_27\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_28\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_29\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_30\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_31\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_32\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_33\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_34\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_35\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_36\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_37\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_38\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_39\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_40\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_41\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_42\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_43\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_44\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_45\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_46\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_47\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_48\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_49\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_50\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_51\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_52\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_53\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_54\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_55\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_56\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_57\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_58\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_59\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_60\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_61\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_62\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_63\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_64\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_65\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_66\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_67\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_68\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_69\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_70\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_71\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_72\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_73\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_74\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_75\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_76\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_77\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_78\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_79\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_80\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_81\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_82\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_83\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_84\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_85\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_86\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_87\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_88\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_89\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_90\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_91\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_92\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_93\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_94\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_95\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_96\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_97\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_98\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_99\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_100\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_101\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_102\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_103\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_104\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_105\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_106\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_107\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_108\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_109\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_110\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_111\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_112\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_113\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_114\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_115\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_116\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_117\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_118\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_119\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_120\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_121\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_122\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_123\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_124\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_125\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_126\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_127\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_128\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_129\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_130\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_131\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_132\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_133\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_134\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_135\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_136\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_137\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_138\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_139\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_140\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_141\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_142\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_143\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_144\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_145\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_146\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_147\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_148\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_149\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_150\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_151\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_152\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_153\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_154\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_155\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_156\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_157\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_158\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_159\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_160\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_161\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_162\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_163\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_164\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_165\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_166\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_167\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_168\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_169\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_170\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_171\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_172\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_173\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_174\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_175\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_176\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_177\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_178\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_179\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_180\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_181\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_182\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_183\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_184\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_185\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_186\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_187\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_188\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_189\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_190\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_191\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_192\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_193\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_194\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_195\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_196\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_197\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_198\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_199\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_200\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_201\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_202\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_203\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_204\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_205\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_206\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_207\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_208\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_209\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_210\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_211\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_212\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_213\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_214\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_215\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_216\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_217\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_218\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_219\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_220\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_221\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_222\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_223\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_224\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_225\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_226\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_227\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_228\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_229\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_230\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_231\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_232\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_233\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_234\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_235\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_236\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_237\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_238\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_239\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_240\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_241\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_242\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_243\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_244\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_245\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_246\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_247\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_248\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_249\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_250\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_251\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_252\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_253\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_254\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_255\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_256\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_257\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_258\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_259\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_260\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_261\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_262\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_263\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_264\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_265\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_266\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_267\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_268\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_269\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_270\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_271\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_272\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_273\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_274\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_275\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_276\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_277\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_278\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_279\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_280\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_281\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_282\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_283\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_284\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_285\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_286\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_287\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_288\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_289\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_290\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_291\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_292\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_293\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_294\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_295\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_296\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_297\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_298\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_299\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_300\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_301\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_302\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_303\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_304\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_305\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_306\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_307\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_308\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_309\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_310\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_311\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_312\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_313\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_314\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_315\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_316\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_317\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_318\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_319\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_320\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_321\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_322\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_323\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_324\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_325\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_326\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_327\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_328\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_329\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_330\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_331\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_332\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_333\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_334\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_335\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_336\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_337\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_338\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_339\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_340\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_341\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_342\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_343\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_344\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_345\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_346\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_347\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_348\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_349\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_350\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_351\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_352\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_353\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_354\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_355\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_356\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_357\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_358\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_359\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-450609aa533b>:59: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  return S[:, None].astype(np.int)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_361\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_362\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_363\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_364\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_365\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_366\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_367\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_368\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_369\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_370\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_371\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_372\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_373\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_374\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_375\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_376\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_377\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_378\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_379\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_380\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_381\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_382\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_383\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_384\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_385\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_386\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_387\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_388\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_389\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_390\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_391\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_392\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_393\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_394\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_395\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_396\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_397\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_398\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_399\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_400\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_401\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_402\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_403\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_404\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_405\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_406\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_407\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_408\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_409\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_410\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_411\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_412\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_413\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_414\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_415\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_416\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_417\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_418\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_419\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_420\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_421\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_422\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_423\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_424\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_425\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_426\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_427\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_428\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_429\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_430\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_431\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_432\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_433\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_434\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_435\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_436\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_437\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_438\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_439\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_440\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_441\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_442\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_443\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_444\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_445\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_446\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_447\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_448\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_449\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_450\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_451\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_452\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_453\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_454\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_455\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_456\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_457\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_458\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_459\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_460\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_461\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_462\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_463\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_464\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_465\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_466\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_467\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_468\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_469\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_470\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_471\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_472\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_473\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_474\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_475\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_476\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_477\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_478\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_479\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_480\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_481\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_482\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_483\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_484\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_485\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_486\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_487\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_488\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_489\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_490\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_491\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_492\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_493\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_494\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_495\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_496\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_497\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_498\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_499\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_500\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_501\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_502\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_503\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_504\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_505\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_506\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_507\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_508\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_509\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_510\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_511\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_512\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_513\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_514\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_515\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_516\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_517\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_518\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_519\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_520\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_521\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_522\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_523\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_524\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_525\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_526\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_527\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_528\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_529\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_530\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_531\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_532\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_533\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_534\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_535\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_536\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_537\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_538\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_539\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_540\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_541\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_542\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_543\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_544\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_545\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_546\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_547\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_548\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_549\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_550\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_551\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_552\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_553\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_554\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_555\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_556\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_557\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_558\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_559\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_560\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_561\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_562\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_563\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_564\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_565\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_566\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_567\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_568\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_569\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_570\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_571\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_572\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_573\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_574\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_575\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_576\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_577\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_578\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_579\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_580\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_581\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_582\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_583\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_584\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_585\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_586\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_587\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_588\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_589\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_590\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_591\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_592\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_593\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_594\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_595\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_596\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_597\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_598\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_599\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_600\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_601\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_602\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_603\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_604\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_605\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_606\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_607\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_608\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_609\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_610\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_611\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_612\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_613\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_614\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_615\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_616\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_617\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_618\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_619\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_620\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_621\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_622\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_623\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_624\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_625\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_626\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_627\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_628\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_629\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_630\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_631\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_632\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_633\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_634\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_635\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_636\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_637\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_638\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_639\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_640\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_641\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_642\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_643\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_644\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_645\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_646\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_647\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_648\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_649\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_650\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_651\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_652\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_653\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_654\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_655\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_656\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_657\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_658\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_659\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_660\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_661\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_662\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_663\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_664\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_665\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_666\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_667\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_668\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_669\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_670\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_671\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_672\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_673\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_674\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_675\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_676\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_677\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_678\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_679\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_680\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_681\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_682\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_683\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_684\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_685\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_686\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_687\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_688\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_689\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_690\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_691\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_692\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_693\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_694\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_695\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_696\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_697\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_698\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_699\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_700\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_701\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_702\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_703\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_704\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_705\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_706\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_707\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_708\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_709\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_710\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_711\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_712\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_713\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_714\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_715\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_716\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_717\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_718\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_719\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_720\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_721\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_722\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_723\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_724\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_725\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_726\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_727\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_728\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_729\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_730\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_731\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_732\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_733\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_734\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_735\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_736\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_737\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_738\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_739\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_740\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_741\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_742\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_743\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_744\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_745\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_746\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_747\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_748\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_749\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_750\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_751\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_752\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_753\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_754\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_755\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_756\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_757\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_758\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_759\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_760\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_761\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_762\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_763\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_764\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_765\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_766\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_767\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_768\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_769\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_770\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_771\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_772\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_773\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_774\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_775\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_776\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_777\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_778\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_779\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_780\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_781\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_782\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_783\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_784\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_785\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_786\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_787\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_788\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_789\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_790\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_791\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_792\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_793\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_794\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_795\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_796\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_797\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_798\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_799\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_800\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_801\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_802\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_803\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_804\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_805\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_806\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_807\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_808\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_809\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_810\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_811\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_812\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_813\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_814\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_815\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_816\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_817\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_818\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_819\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_820\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_821\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_822\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_823\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_824\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_825\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_826\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_827\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_828\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_829\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_830\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_831\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_832\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_833\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_834\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_835\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_836\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_837\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_838\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_839\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_840\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_841\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_842\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_843\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_844\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_845\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_846\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_847\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_848\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_849\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_850\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_851\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_852\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_853\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_854\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_855\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_856\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_857\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_858\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_859\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_860\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_861\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_862\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_863\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_864\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_865\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_866\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_867\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_868\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_869\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_870\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_871\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_872\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_873\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_874\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_875\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_876\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_877\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_878\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_879\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_880\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_881\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_882\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_883\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_884\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_885\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_886\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_887\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_888\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_889\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_890\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_891\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_892\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_893\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_894\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_895\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_896\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_897\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_898\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_899\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_900\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_901\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_902\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_903\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_904\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_905\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_906\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_907\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_908\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_909\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_910\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_911\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_912\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_913\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_914\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_915\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_916\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_917\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_918\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_919\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_920\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_921\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_922\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_923\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_924\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_925\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_926\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_927\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_928\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_929\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_930\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_931\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_932\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_933\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_934\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_935\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_936\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_937\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_938\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_939\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_940\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_941\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_942\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_943\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_944\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_945\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_946\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_947\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_948\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_949\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_950\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_951\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_952\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_953\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_954\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_955\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_956\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_957\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_958\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_959\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_960\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_961\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_962\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_963\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_964\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_965\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_966\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_967\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_968\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_969\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_970\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_971\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_972\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_973\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_974\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_975\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_976\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_977\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_978\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_979\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_980\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_981\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_982\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_983\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_984\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_985\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_986\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_987\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_988\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_989\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_990\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_991\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_992\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_993\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_994\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_995\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_996\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_997\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_998\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_999\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1000\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1001\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1002\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1003\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1004\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1005\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1006\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1007\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1008\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1009\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1010\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1011\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1012\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1013\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1014\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1015\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1016\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1017\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1018\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1019\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1020\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1021\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1022\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1023\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1024\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1025\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1026\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1027\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1028\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1029\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1030\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1031\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1032\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1033\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1034\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1035\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1036\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1037\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1038\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1039\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1040\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1041\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1042\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1043\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1044\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1045\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1046\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1047\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1048\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1049\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1050\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1051\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1052\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1053\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1054\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1055\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1056\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1057\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1058\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1059\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1060\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1061\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1062\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1063\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1064\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1065\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1066\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1067\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1068\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1069\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1070\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1071\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1072\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1073\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1074\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1075\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1076\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1077\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1078\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1079\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1080\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1081\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1082\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1083\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1084\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1085\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1086\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1087\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1088\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1089\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1090\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1091\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1092\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1093\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1094\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1095\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1096\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1097\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1098\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1099\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1100\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1101\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1102\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1103\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1104\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1105\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1106\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1107\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1108\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1109\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1110\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1111\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1112\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1113\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1114\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1115\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1116\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1117\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1118\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1119\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1120\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1121\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1122\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1123\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1124\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1125\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1126\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1127\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1128\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1129\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1130\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1131\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1132\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1133\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1134\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1135\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1136\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1137\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1138\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1139\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1140\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1141\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1142\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1143\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1144\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1145\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1146\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1147\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1148\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1149\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1150\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1151\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1152\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1153\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1154\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1155\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1156\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1157\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1158\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1159\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1160\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1161\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1162\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1163\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1164\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1165\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1166\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1167\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1168\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1169\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1170\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1171\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1172\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1173\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1174\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1175\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1176\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1177\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1178\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1179\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1180\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1181\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1182\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1183\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1184\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1185\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1186\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1187\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1188\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1189\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1190\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1191\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1192\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1193\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1194\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1195\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1196\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1197\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1198\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1199\n",
            "Experiment dir : search-GA-BiObj-macro-20221227-060539/arch_1200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!zip -r /content/file.zip /content/search-GA-BiObj-macro-20221227-165159"
      ],
      "metadata": {
        "id": "sIRrcJv_5tYp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}