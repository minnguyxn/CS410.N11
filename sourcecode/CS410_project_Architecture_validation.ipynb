{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e7b488a699f34e839d438572f93cf194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b90be05d2ff74f658f669df5b94f464f",
              "IPY_MODEL_7a5a92c324774bfca676389c4bf4b608",
              "IPY_MODEL_a93f478fa5614288ba638b7a1ec1771e"
            ],
            "layout": "IPY_MODEL_f45b076574c440519de0a0cce474dc10"
          }
        },
        "b90be05d2ff74f658f669df5b94f464f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a763d2b41fc74131a6859c1c9133d74a",
            "placeholder": "​",
            "style": "IPY_MODEL_09d5c846c1fb44e78e33f737181bb6f9",
            "value": "100%"
          }
        },
        "7a5a92c324774bfca676389c4bf4b608": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ef12fb137034500891d4500b4f8c21d",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92198fe269f54454b08f59f328744443",
            "value": 170498071
          }
        },
        "a93f478fa5614288ba638b7a1ec1771e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5329a5f2ba3346c5b9b147d2c92d3339",
            "placeholder": "​",
            "style": "IPY_MODEL_3359862780de4ab2af3c9b1195646511",
            "value": " 170498071/170498071 [00:03&lt;00:00, 53068441.76it/s]"
          }
        },
        "f45b076574c440519de0a0cce474dc10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a763d2b41fc74131a6859c1c9133d74a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09d5c846c1fb44e78e33f737181bb6f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ef12fb137034500891d4500b4f8c21d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92198fe269f54454b08f59f328744443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5329a5f2ba3346c5b9b147d2c92d3339": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3359862780de4ab2af3c9b1195646511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import logging\n",
        "import argparse\n",
        "import numpy as np\n",
        "import shutil\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable"
      ],
      "metadata": {
        "id": "kkhbid2ykRVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cudnn.enabled = True\n",
        "cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "O37cC70SkuFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 0"
      ],
      "metadata": {
        "id": "DfAHlpEMk1S1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)"
      ],
      "metadata": {
        "id": "uTTzFiSsky8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_acc = 0"
      ],
      "metadata": {
        "id": "kxpm_d65k_YZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Cutout(object):\n",
        "    def __init__(self, length):\n",
        "        self.length = length\n",
        "\n",
        "    def __call__(self, img):\n",
        "        h, w = img.size(1), img.size(2)\n",
        "        mask = np.ones((h, w), np.float32)\n",
        "        y = np.random.randint(h)\n",
        "        x = np.random.randint(w)\n",
        "\n",
        "        y1 = np.clip(y - self.length // 2, 0, h)\n",
        "        y2 = np.clip(y + self.length // 2, 0, h)\n",
        "        x1 = np.clip(x - self.length // 2, 0, w)\n",
        "        x2 = np.clip(x + self.length // 2, 0, w)\n",
        "\n",
        "        mask[y1: y2, x1: x2] = 0.\n",
        "        mask = torch.from_numpy(mask)\n",
        "        mask = mask.expand_as(img)\n",
        "        img *= mask\n",
        "        return img"
      ],
      "metadata": {
        "id": "uWp_xSWdl4oG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _data_transforms_cifar10(cutout):\n",
        "    CIFAR_MEAN = [0.49139968, 0.48215827, 0.44653124]\n",
        "    CIFAR_STD = [0.24703233, 0.24348505, 0.26158768]\n",
        "\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    if cutout:\n",
        "        train_transform.transforms.append(Cutout(16))\n",
        "\n",
        "    train_transform.transforms.append(transforms.Normalize(CIFAR_MEAN, CIFAR_STD))\n",
        "\n",
        "    valid_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(CIFAR_MEAN, CIFAR_STD),\n",
        "    ])\n",
        "    return train_transform, valid_transform, valid_transform"
      ],
      "metadata": {
        "id": "HnSqpAHSlskr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from copy import copy\n",
        "from abc import ABC, abstractmethod\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "class Decoder(ABC):\n",
        "    \"\"\"\n",
        "    Abstract genome decoder class.\n",
        "    \"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def __init__(self, list_genome):\n",
        "        \"\"\"\n",
        "        :param list_genome: genome represented as a list.\n",
        "        \"\"\"\n",
        "        self._genome = list_genome\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_model(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class ChannelBasedDecoder(Decoder):\n",
        "    \"\"\"\n",
        "    Channel based decoder that deals with encapsulating constructor logic.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, list_genome, channels, repeats=None):\n",
        "        \"\"\"\n",
        "        Constructor.\n",
        "        :param list_genome: list, genome describing the connections in a network.\n",
        "        :param channels: list, list of tuples describing the channel size changes.\n",
        "        :param repeats: None | list, list of integers describing how many times to repeat each phase.\n",
        "        \"\"\"\n",
        "        super().__init__(list_genome)\n",
        "\n",
        "        self._model = None\n",
        "\n",
        "        # First, we remove all inactive phases.\n",
        "        self._genome = self.get_effective_genome(list_genome)\n",
        "        self._channels = channels[:len(self._genome)]\n",
        "\n",
        "        # Use the provided repeats list, or a list of all ones (only repeat each phase once).\n",
        "        if repeats is not None:\n",
        "            # First select only the repeats that are active in the list_genome.\n",
        "            active_repeats = []\n",
        "            for idx, gene in enumerate(list_genome):\n",
        "                if phase_active(gene):\n",
        "                    active_repeats.append(repeats[idx])\n",
        "\n",
        "            self.adjust_for_repeats(active_repeats)\n",
        "        else:\n",
        "            # Each phase only repeated once.\n",
        "            self._repeats = [1 for _ in self._genome]\n",
        "\n",
        "        # If we had no active nodes, our model is just the identity, and we stop constructing.\n",
        "        if not self._genome:\n",
        "            self._model = Identity()\n",
        "\n",
        "        # print(list_genome)\n",
        "\n",
        "    def adjust_for_repeats(self, repeats):\n",
        "        \"\"\"\n",
        "        Adjust for repetition of phases.\n",
        "        :param repeats:\n",
        "        \"\"\"\n",
        "        self._repeats = repeats\n",
        "\n",
        "        # Adjust channels and genome to agree with repeats.\n",
        "        repeated_genome = []\n",
        "        repeated_channels = []\n",
        "        for i, repeat in enumerate(self._repeats):\n",
        "            for j in range(repeat):\n",
        "                if j == 0:\n",
        "                    # This is the first instance of this repeat, we need to use the (in, out) channel convention.\n",
        "                    repeated_channels.append((self._channels[i][0], self._channels[i][1]))\n",
        "                else:\n",
        "                    # This is not the first instance, use the (out, out) convention.\n",
        "                    repeated_channels.append((self._channels[i][1], self._channels[i][1]))\n",
        "\n",
        "                repeated_genome.append(self._genome[i])\n",
        "\n",
        "        self._genome = repeated_genome\n",
        "        self._channels = repeated_channels\n",
        "\n",
        "    def build_layers(self, phases):\n",
        "        \"\"\"\n",
        "        Build up the layers with transitions.\n",
        "        :param phases: list of phases\n",
        "        :return: list of layers (the model).\n",
        "        \"\"\"\n",
        "        layers = []\n",
        "        last_phase = phases.pop()\n",
        "        for phase, repeat in zip(phases, self._repeats):\n",
        "            for _ in range(repeat):\n",
        "                layers.append(phase)\n",
        "            layers.append(nn.MaxPool2d(kernel_size=2, stride=2))  # TODO: Generalize this, or consider a new genome.\n",
        "\n",
        "        layers.append(last_phase)\n",
        "        return layers\n",
        "\n",
        "    @staticmethod\n",
        "    def get_effective_genome(genome):\n",
        "        \"\"\"\n",
        "        Get only the parts of the genome that are active.\n",
        "        :param genome: list, represents the genome\n",
        "        :return: list\n",
        "        \"\"\"\n",
        "        return [gene for gene in genome if phase_active(gene)]\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_model(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class HourGlassDecoder(Decoder):\n",
        "    \"\"\"\n",
        "    Decoder that deals with HourGlass-type networks.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, genome, n_stacks, out_feature_maps):\n",
        "        \"\"\"\n",
        "        Constructor.\n",
        "        :param genome: list, list of ints.\n",
        "        :param n_stacks: int, number of hourglasses to use.\n",
        "        :param out_feature_maps: int, number of output feature maps.\n",
        "        \"\"\"\n",
        "        super().__init__(genome)\n",
        "\n",
        "        self.n_stacks = n_stacks\n",
        "        self.out_feature_maps = out_feature_maps\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_model(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    @staticmethod\n",
        "    @abstractmethod\n",
        "    def check_genome(genome):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class LOSHourGlassDecoder(HourGlassDecoder, nn.Module):\n",
        "    \"\"\"\n",
        "    Line of sight HourGlass decoder.\n",
        "    \"\"\"\n",
        "\n",
        "    STEP_TOLERANCE = 2  # A network can step as much as\n",
        "    GENE_LB = 0  # Gene must be greater than this value.\n",
        "    GENE_UB = 6  # Gene must be less than this value.\n",
        "\n",
        "    def __init__(self, genome, n_stacks, out_feature_maps, pre_hourglass_channels=32, hourglass_channels=64):\n",
        "        \"\"\"\n",
        "        Constructor.\n",
        "        :param genome: list, list of ints satisfying properties defined in self.valid_genome.\n",
        "        :param n_stacks: int, number of hourglasses to use.\n",
        "        :param out_feature_maps, int, number of output feature maps.\n",
        "        \"\"\"\n",
        "        HourGlassDecoder.__init__(self, genome, n_stacks, out_feature_maps)\n",
        "        nn.Module.__init__(self)\n",
        "\n",
        "        self.pre_hourglass_channels = pre_hourglass_channels\n",
        "        self.hourglass_channels = hourglass_channels\n",
        "\n",
        "        self.check_genome(genome)\n",
        "\n",
        "        # Initial resolution reducing, takes 256 x 256 to 64 x 64\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.Conv2d(3, self.pre_hourglass_channels, kernel_size=7, stride=2, padding=3, bias=True),\n",
        "            nn.BatchNorm2d(self.pre_hourglass_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            HourGlassResidual(self.pre_hourglass_channels, self.pre_hourglass_channels)\n",
        "        )\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.secondary = nn.Sequential(\n",
        "            HourGlassResidual(self.pre_hourglass_channels, self.pre_hourglass_channels),\n",
        "            HourGlassResidual(self.pre_hourglass_channels, self.hourglass_channels)\n",
        "        )\n",
        "\n",
        "        #\n",
        "        # Evolved part follows.\n",
        "        #\n",
        "        graph = LOSComputationGraph(genome)  # The evolved computation graph.\n",
        "        hg_channels = self.hourglass_channels * LOSHourGlassBlock.EXPANSION  # Number of channels output by the hourglass.\n",
        "\n",
        "        # List of hourglasses, deep copy of hourglass constructed above.\n",
        "        hourglasses = [LOSHourGlassBlock(graph, self.hourglass_channels, hg_channels)]\n",
        "\n",
        "        # Lin layers run on the output of the hourglass.\n",
        "        first_lin = [Lin(hg_channels, hg_channels)]\n",
        "        second_lin = [Lin(hg_channels, self.hourglass_channels)]\n",
        "\n",
        "        # 1x1 convs to adjust channels to fit number of scoremaps.\n",
        "        to_score_map = [nn.Conv2d(self.hourglass_channels, out_feature_maps, kernel_size=1, bias=True)]\n",
        "        # 1x1 convs to adjust scoremap back to appropriate feature map count.\n",
        "        from_score_map = [nn.Conv2d(out_feature_maps, self.hourglass_channels + self.pre_hourglass_channels, kernel_size=1, bias=True)]\n",
        "\n",
        "        # 1x1 convs for the skip connection that skips the hourglass.\n",
        "        skip_convs = [nn.Conv2d(self.hourglass_channels + self.pre_hourglass_channels, self.hourglass_channels + self.pre_hourglass_channels,\n",
        "                                kernel_size=1, bias=True)]\n",
        "\n",
        "        skip_channels = self.pre_hourglass_channels\n",
        "\n",
        "        #\n",
        "        # The above and proceeding code is overly complex to deal with the fact that the first skip connection will\n",
        "        # have less channels than the rest of the network, as specified in the original implementation.\n",
        "        #\n",
        "\n",
        "        for i in range(1, n_stacks):\n",
        "            hourglasses.append(LOSHourGlassBlock(graph, self.hourglass_channels + skip_channels, hg_channels))\n",
        "            first_lin.append(Lin(hg_channels, hg_channels))\n",
        "\n",
        "            to_score_map.append(nn.Conv2d(self.hourglass_channels, out_feature_maps, kernel_size=1, bias=True))\n",
        "            second_lin.append(Lin(hg_channels, self.hourglass_channels))\n",
        "\n",
        "            # We only need go back to the original channel sizes from the score maps n - 1 times.\n",
        "            if i < n_stacks - 1:\n",
        "                skip_convs.append(nn.Conv2d(hg_channels, hg_channels, kernel_size=1, bias=True))\n",
        "                from_score_map.append(nn.Conv2d(out_feature_maps, hg_channels, kernel_size=1,\n",
        "                                                bias=True))\n",
        "\n",
        "            skip_channels = self.hourglass_channels\n",
        "\n",
        "        # Register everything by converting to ModuleLists.\n",
        "        self.hourglasses = nn.ModuleList(hourglasses)\n",
        "        self.first_lin = nn.ModuleList(first_lin)\n",
        "        self.to_score_map = nn.ModuleList(to_score_map)\n",
        "        self.from_score_map = nn.ModuleList(from_score_map)\n",
        "        self.second_lin = nn.ModuleList(second_lin)\n",
        "        self.skip_convs = nn.ModuleList(skip_convs)\n",
        "\n",
        "    @staticmethod\n",
        "    def check_genome(genome):\n",
        "        \"\"\"\n",
        "        Make sure the genome is valid.\n",
        "        :param genome: list, list of ints, representing the genome.\n",
        "        :raises AssertionError: if genome is not valid.\n",
        "        \"\"\"\n",
        "        assert isinstance(genome[0], int), \"Genome should be a list of integers.\"\n",
        "\n",
        "        for gene in genome:\n",
        "            assert LOSHourGlassDecoder.GENE_LB < gene < LOSHourGlassDecoder.GENE_UB, \\\n",
        "                \"{} is an invalid gene value, must be in range [{}, {}]\".format(gene,\n",
        "                                                                                LOSHourGlassDecoder.GENE_LB,\n",
        "                                                                                LOSHourGlassDecoder.GENE_UB)\n",
        "        for i in range(len(genome) - 1):\n",
        "            step = abs(genome[i] - genome[i + 1])\n",
        "            assert step <= LOSHourGlassDecoder.STEP_TOLERANCE, \\\n",
        "                \"Attempted to step {} resolutions, cannot step more than 2 resolutions.\".format(step)\n",
        "\n",
        "    def get_model(self):\n",
        "        \"\"\"\n",
        "        In other decoders, we'd return a module object, but since self is an nn.Module, we return self.\n",
        "        :return: self\n",
        "        \"\"\"\n",
        "        return self\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward operation.\n",
        "        :param x: Variable, input\n",
        "        :return: list, list of Variables, intermediate and final score maps.\n",
        "        \"\"\"\n",
        "        maps = []\n",
        "\n",
        "        x = self.initial(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        skip = x.clone()\n",
        "\n",
        "        x = self.secondary(x)\n",
        "\n",
        "        for i in range(self.n_stacks):\n",
        "            y = self.hourglasses[i](x)\n",
        "            y = self.first_lin[i](y)\n",
        "            y = self.second_lin[i](y)\n",
        "\n",
        "            next_skip = y.clone()\n",
        "\n",
        "            score_map = self.to_score_map[i](y)\n",
        "\n",
        "            maps.append(score_map)\n",
        "\n",
        "            # We only need to map back from the score feature maps and do skip connection n - 1 times.\n",
        "            if i < self.n_stacks - 1:\n",
        "                z = self.from_score_map[i](score_map)\n",
        "                a = torch.cat((y, skip), dim=1)\n",
        "                a = self.skip_convs[i](a)\n",
        "\n",
        "                x = z + a\n",
        "\n",
        "            skip = next_skip\n",
        "\n",
        "        return maps\n",
        "\n",
        "\n",
        "class Lin(nn.Module):\n",
        "    \"\"\"\n",
        "    \"Lin\" layer as implemented in: https://github.com/umich-vl/pose-hg-demo/blob/master/stacked-hourglass-model.lua\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        \"\"\"\n",
        "        Constructor.\n",
        "        :param in_channels: int, input channels.\n",
        "        :param out_channels: int, desired output channels.\n",
        "        \"\"\"\n",
        "        super(Lin, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=True),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "class LOSHourGlassBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    HourGlassBlock, repeated in an hourglass-type network.\n",
        "    \"\"\"\n",
        "\n",
        "    EXPANSION = 2  # Hour glass block will increase channels by a factor of 2.\n",
        "\n",
        "    def __init__(self, graph, in_channels, out_channels, operating_channels=64):\n",
        "        \"\"\"\n",
        "        Constructor.\n",
        "        :param graph: decoder.LOSComputationGraph, represents the computation flow.\n",
        "        :param in_channels: int, number of input channels.\n",
        "        :param out_channels: int, number of output channels.\n",
        "        \"\"\"\n",
        "        super(LOSHourGlassBlock, self).__init__()\n",
        "\n",
        "        self.operating_channels = operating_channels\n",
        "\n",
        "        self.graph = graph\n",
        "        samplers = []\n",
        "        nodes, _ = zip(*self.graph.items())\n",
        "        nodes = [None] + list(nodes) + [None]  # Append none's to downsample input and upsample output if needed.\n",
        "        for i in range(len(nodes[:-1])):\n",
        "            samplers.append(self.make_sampling(nodes[i], nodes[i + 1]))\n",
        "\n",
        "        self.samplers = nn.ModuleList(samplers)\n",
        "\n",
        "        skip_ops = []  # HourGlassResiduals for the skip connections\n",
        "        for node in graph.keys():\n",
        "            if node.residual:\n",
        "                skip_ops.append(HourGlassResidual(self.operating_channels, self.operating_channels))\n",
        "\n",
        "            else:\n",
        "                skip_ops.append(None)  # Filler to make the indices match\n",
        "\n",
        "        last_node = list(graph.keys())[-1]\n",
        "        res = last_node.residual_node\n",
        "        if res:\n",
        "            # If the last node receives a residual, we need to change the operation to output the right channel size.\n",
        "            skip_ops[res.idx] = HourGlassResidual(self.operating_channels, out_channels)\n",
        "\n",
        "        self.skip_ops = nn.ModuleList(skip_ops)\n",
        "\n",
        "        path_ops = [HourGlassResidual(in_channels, self.operating_channels)]\n",
        "        for i in range(len(graph) - 2):\n",
        "            path_ops.append(HourGlassResidual(self.operating_channels, self.operating_channels))\n",
        "\n",
        "        path_ops.append(HourGlassResidual(self.operating_channels, out_channels))\n",
        "\n",
        "        self.path_ops = nn.ModuleList(path_ops)\n",
        "\n",
        "    @staticmethod\n",
        "    def make_sampling(prev_node, next_node):\n",
        "        \"\"\"\n",
        "        Determine the factor of up/down sampling needed to move between two nodes.\n",
        "        :param prev_node: LOSComputationGraph.Node | None.\n",
        "        :param next_node: LOSComputationGraph.Node.\n",
        "        :return: nn.MaxPool2d | nn.Upsample\n",
        "        \"\"\"\n",
        "        if prev_node is None:\n",
        "            # We're dealing with the first node (idx 0) so we need a placeholder node.\n",
        "            prev_node = LOSComputationGraph.Node(1, -1)\n",
        "\n",
        "        if next_node is None:\n",
        "            next_node = LOSComputationGraph.Node(1, -1)\n",
        "\n",
        "        if prev_node.resolution == next_node.resolution:\n",
        "            # Nothing to be done.\n",
        "            return Identity()\n",
        "\n",
        "        elif prev_node.resolution > next_node.resolution:\n",
        "            # We need to downsample.\n",
        "            s = int(prev_node.resolution / next_node.resolution)\n",
        "            return nn.MaxPool2d(kernel_size=2, stride=s)\n",
        "\n",
        "        else:\n",
        "            # We need to upsample.\n",
        "            f = int(next_node.resolution / prev_node.resolution)\n",
        "            return nn.Upsample(scale_factor=f, mode=\"nearest\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        residuals = [None for _ in range(len(self.graph))]\n",
        "\n",
        "        for i, (node, _) in enumerate(self.graph.items()):\n",
        "            x = self.samplers[i](x)\n",
        "\n",
        "            x = self.path_ops[i](x)\n",
        "\n",
        "            if node.residual:\n",
        "                residuals[i] = self.skip_ops[i](x.clone())\n",
        "\n",
        "            res = node.residual_node\n",
        "            if res:\n",
        "                # Current node receives a residual connection.\n",
        "                x += residuals[res.idx]\n",
        "                residuals[res.idx] = None  # Free some memory, we'll never need this again.\n",
        "\n",
        "        return self.samplers[-1](x)\n",
        "\n",
        "\n",
        "class LOSComputationGraph:\n",
        "    \"\"\"\n",
        "    Graph to hold information about the computation going on in\n",
        "    \"\"\"\n",
        "    class Node:\n",
        "        \"\"\"\n",
        "        Node to hold information.\n",
        "        \"\"\"\n",
        "        def __init__(self, resolution, idx, residual=False):\n",
        "            \"\"\"\n",
        "            Constructor.\n",
        "            :param resolution: int, the resolution of the image at this point.\n",
        "            :param idx: int, the index of the node in the graph (feed-forward, so this is ok).\n",
        "            :param residual: bool, true if output of this node is needed at some point later in the graph.\n",
        "            \"\"\"\n",
        "            self.resolution, self.idx, self.residual = resolution, idx, residual\n",
        "            self.residual_node = None  # If this node receives a residual, store it here.\n",
        "\n",
        "        def __repr__(self):\n",
        "            residual_str = \", saves residual\" if self.residual else \"\"\n",
        "            return \"<Node index: {} resolution: {}\".format(self.idx, self.resolution) + residual_str + \">\"\n",
        "\n",
        "        def __str__(self):\n",
        "            return self.__repr__()\n",
        "\n",
        "        def __lt__(self, other):\n",
        "            assert isinstance(other, LOSComputationGraph.Node)\n",
        "            return self.idx < other.idx\n",
        "\n",
        "    def __init__(self, genome, under_connect=True):\n",
        "        \"\"\"\n",
        "        Make the computation graph specified by the genoms.\n",
        "        :param genome: list, list of ints representing a genome.\n",
        "        \"\"\"\n",
        "        self.graph = LOSComputationGraph.make_graph(genome, under_connect)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.graph)\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self.graph.__iter__()\n",
        "\n",
        "    def items(self):\n",
        "        return self.graph.items()\n",
        "\n",
        "    def keys(self):\n",
        "        return self.graph.keys()\n",
        "\n",
        "    def values(self):\n",
        "        return self.graph.values()\n",
        "\n",
        "    def get_residual(self, node):\n",
        "        \"\"\"\n",
        "        Determines if a particular node in the graph gets a residual connection.\n",
        "        :param node: LOSComputationGraph.Node.\n",
        "        :return: LOSComputationGraph.Node | None\n",
        "        \"\"\"\n",
        "        if node in self.graph:\n",
        "            for dep in self.graph[node]:\n",
        "                if dep.resolution == node.resolution and dep.residual:\n",
        "                    return dep\n",
        "\n",
        "        return None\n",
        "\n",
        "    @staticmethod\n",
        "    def make_graph(genome, under_connect=True):\n",
        "        \"\"\"\n",
        "        Make the computation graph.\n",
        "        The is not exactly an adjacency list... The normal forward path through the network is as expected, but the\n",
        "            skip connections are only listed in the receiving nodes, rather than the sending nodes.\n",
        "            This makes things much easier when actually forward propagating.\n",
        "        :param genome: list, list of ints representing a genome.\n",
        "        :param under_connect: bool, if false, we will not allow \"under connections\".\n",
        "            Where an under connection connects nodes that may occur below the current path. Ex:\n",
        "            | X ----->  X ----->  X\n",
        "            |   X --> X .. X --> X\n",
        "            |     X  ......  X\n",
        "            Where arrows are the normal residual connections and the dots are the optional under connections.\n",
        "        :return: OrderedDict, dict of lists, adjacency list describing the computation graph.\n",
        "        \"\"\"\n",
        "        adj = OrderedDict()\n",
        "\n",
        "        nodes = [LOSComputationGraph.Node(pow(2, -(gene - 1)), i) for i, gene in enumerate(genome)]\n",
        "\n",
        "        # Construct the initial path through the graph, each node is connected to the one at the index in front of it.\n",
        "        # Read as \"Gene i\" and \"Gene i plus one\".\n",
        "        for i, (gene_i, gene_ipo) in enumerate(zip(nodes, nodes[1:])):\n",
        "            adj[gene_i] = [gene_ipo]\n",
        "\n",
        "        adj[nodes[-1]] = []\n",
        "\n",
        "        previous_resolutions = {}\n",
        "        previous_node = nodes[0]\n",
        "        for node, adj_list in adj.items():\n",
        "            if node.resolution in previous_resolutions:\n",
        "                # We have found a node that occurred before the current one with the same resolution.\n",
        "\n",
        "                if previous_node.resolution < node.resolution or \\\n",
        "                   previous_node.resolution > node.resolution and under_connect:\n",
        "                    # Either we upsampled or downsampled. We always mark a residual and update the previous resolution\n",
        "                    # is we upsample. If we're allowing connections under the path, we do the same.\n",
        "                    previous_resolutions[node.resolution].residual = True\n",
        "                    node.residual_node = previous_resolutions[node.resolution]\n",
        "                    previous_resolutions[node.resolution] = node\n",
        "\n",
        "                else:\n",
        "                    # There was no change in resolution, just update previous_resolutions at this value to be\n",
        "                    # the current node.\n",
        "                    previous_resolutions[node.resolution] = node\n",
        "\n",
        "            else:\n",
        "                # We did not find a node before the current one that had its particular resolution.\n",
        "                previous_resolutions[node.resolution] = node\n",
        "\n",
        "            previous_node = node\n",
        "\n",
        "        return adj\n",
        "\n",
        "\n",
        "class HourGlassResidual(nn.Module):\n",
        "    \"\"\"\n",
        "    Hour glass residual, As defined in https://arxiv.org/pdf/1603.06937.pdf.\n",
        "    Code converted from original lua: https://github.com/umich-vl/pose-hg-demo/blob/master/residual.lua\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(HourGlassResidual, self).__init__()\n",
        "\n",
        "        # 1x1 convolution to make the residual connection's channels match the output channels.\n",
        "        self.skip_layer = Identity() if in_channels == out_channels else \\\n",
        "            nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=True), nn.BatchNorm2d(out_channels))\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels // 2, kernel_size=1, bias=True),\n",
        "            nn.BatchNorm2d(out_channels // 2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels // 2, out_channels // 2, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "            nn.BatchNorm2d(out_channels // 2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels // 2, out_channels, kernel_size=1, bias=True),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Apply forward propagation operation.\n",
        "        :param x: Variable, input.\n",
        "        :return: Variable\n",
        "        \"\"\"\n",
        "        residual = x\n",
        "        out = self.model(x)\n",
        "        return out + self.skip_layer(residual)\n",
        "\n",
        "\n",
        "class ResidualGenomeDecoder(ChannelBasedDecoder):\n",
        "    \"\"\"\n",
        "    Genetic CNN genome decoder with residual bit.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, list_genome, channels, preact=False, repeats=None):\n",
        "        \"\"\"\n",
        "        Constructor.\n",
        "        :param list_genome: list, genome describing the connections in a network.\n",
        "        :param channels: list, list of tuples describing the channel size changes.\n",
        "        :param repeats: None | list, list of integers describing how many times to repeat each phase.\n",
        "        \"\"\"\n",
        "        super().__init__(list_genome, channels, repeats=repeats)\n",
        "\n",
        "        if self._model is not None:\n",
        "            return  # Exit if the parent constructor set the model.\n",
        "\n",
        "        # Build up the appropriate number of phases.\n",
        "        phases = []\n",
        "        for idx, (gene, (in_channels, out_channels)) in enumerate(zip(self._genome, self._channels)):\n",
        "            phases.append(ResidualPhase(gene, in_channels, out_channels, idx, preact=preact))\n",
        "\n",
        "        self._model = nn.Sequential(*self.build_layers(phases))\n",
        "\n",
        "    def get_model(self):\n",
        "        \"\"\"\n",
        "        :return: nn.Module\n",
        "        \"\"\"\n",
        "        return self._model\n",
        "\n",
        "\n",
        "class ResidualPhase(nn.Module):\n",
        "    \"\"\"\n",
        "    Residual Genome phase.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, gene, in_channels, out_channels, idx, preact=False):\n",
        "        \"\"\"\n",
        "        Constructor.\n",
        "        :param gene: list, element of genome describing connections in this phase.\n",
        "        :param in_channels: int, number of input channels.\n",
        "        :param out_channels: int, number of output channels.\n",
        "        :param idx: int, index in the network.\n",
        "        :param preact: should we use the preactivation scheme?\n",
        "        \"\"\"\n",
        "        super(ResidualPhase, self).__init__()\n",
        "\n",
        "        self.channel_flag = in_channels != out_channels  # Flag to tell us if we need to increase channel size.\n",
        "        self.first_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1 if idx != 0 else 3, stride=1, bias=False)\n",
        "        self.dependency_graph = ResidualPhase.build_dependency_graph(gene)\n",
        "\n",
        "        if preact:\n",
        "            node_constructor = PreactResidualNode\n",
        "\n",
        "        else:\n",
        "            node_constructor = ResidualNode\n",
        "\n",
        "        nodes = []\n",
        "        for i in range(len(gene)):\n",
        "            if len(self.dependency_graph[i + 1]) > 0:\n",
        "                nodes.append(node_constructor(out_channels, out_channels))\n",
        "            else:\n",
        "                nodes.append(None)  # Module list will ignore NoneType.\n",
        "\n",
        "        self.nodes = nn.ModuleList(nodes)\n",
        "\n",
        "        #\n",
        "        # At this point, we know which nodes will be receiving input from where.\n",
        "        # So, we build the 1x1 convolutions that will deal with the depth-wise concatenations.\n",
        "        #\n",
        "        conv1x1s = [Identity()] + [Identity() for _ in range(max(self.dependency_graph.keys()))]\n",
        "        for node_idx, dependencies in self.dependency_graph.items():\n",
        "            if len(dependencies) > 1:\n",
        "                conv1x1s[node_idx] = \\\n",
        "                    nn.Conv2d(len(dependencies) * out_channels, out_channels, kernel_size=1, bias=False)\n",
        "\n",
        "        self.processors = nn.ModuleList(conv1x1s)\n",
        "        self.out = nn.Sequential(\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def build_dependency_graph(gene):\n",
        "        \"\"\"\n",
        "        Build a graph describing the connections of a phase.\n",
        "        \"Repairs\" made are as follows:\n",
        "            - If a node has no input, but gives output, connect it to the input node (index 0 in outputs).\n",
        "            - If a node has input, but no output, connect it to the output node (value returned from forward method).\n",
        "        :param gene: gene describing the phase connections.\n",
        "        :return: dict\n",
        "        \"\"\"\n",
        "        graph = {}\n",
        "        residual = gene[-1][0] == 1\n",
        "\n",
        "        # First pass, build the graph without repairs.\n",
        "        graph[1] = []\n",
        "        for i in range(len(gene) - 1):\n",
        "            graph[i + 2] = [j + 1 for j in range(len(gene[i])) if gene[i][j] == 1]\n",
        "\n",
        "        graph[len(gene) + 1] = [0] if residual else []\n",
        "\n",
        "        # Determine which nodes, if any, have no inputs and/or outputs.\n",
        "        no_inputs = []\n",
        "        no_outputs = []\n",
        "        for i in range(1, len(gene) + 1):\n",
        "            if len(graph[i]) == 0:\n",
        "                no_inputs.append(i)\n",
        "\n",
        "            has_output = False\n",
        "            for j in range(i + 1, len(gene) + 2):\n",
        "                if i in graph[j]:\n",
        "                    has_output = True\n",
        "                    break\n",
        "\n",
        "            if not has_output:\n",
        "                no_outputs.append(i)\n",
        "\n",
        "        for node in no_outputs:\n",
        "            if node not in no_inputs:\n",
        "                # No outputs, but has inputs. Connect to output node.\n",
        "                graph[len(gene) + 1].append(node)\n",
        "\n",
        "        for node in no_inputs:\n",
        "            if node not in no_outputs:\n",
        "                # No inputs, but has outputs. Connect to input node.\n",
        "                graph[node].append(0)\n",
        "\n",
        "        return graph\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.channel_flag:\n",
        "            x = self.first_conv(x)\n",
        "\n",
        "        outputs = [x]\n",
        "\n",
        "        for i in range(1, len(self.nodes) + 1):\n",
        "            if not self.dependency_graph[i]:  # Empty list, no outputs to give.\n",
        "                outputs.append(None)\n",
        "\n",
        "            else:\n",
        "                outputs.append(self.nodes[i - 1](self.process_dependencies(i, outputs)))\n",
        "\n",
        "        return self.out(self.process_dependencies(len(self.nodes) + 1, outputs))\n",
        "\n",
        "    def process_dependencies(self, node_idx, outputs):\n",
        "        \"\"\"\n",
        "        Process dependencies with a depth-wise concatenation and\n",
        "        :param node_idx: int,\n",
        "        :param outputs: list, current outputs\n",
        "        :return: Variable\n",
        "        \"\"\"\n",
        "        return self.processors[node_idx](torch.cat([outputs[i] for i in self.dependency_graph[node_idx]], dim=1))\n",
        "\n",
        "\n",
        "class ResidualNode(nn.Module):\n",
        "    \"\"\"\n",
        "    Basic computation unit.\n",
        "    Does convolution, batchnorm, and relu (in this order).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1,\n",
        "                 kernel_size=3, padding=1, bias=False):\n",
        "        \"\"\"\n",
        "        Constructor.\n",
        "        Default arguments preserve dimensionality of input.\n",
        "        :param in_channels: input to the node.\n",
        "        :param out_channels: output channels from the node.\n",
        "        :param stride: stride of convolution, default 1.\n",
        "        :param kernel_size: size of convolution kernel, default 3.\n",
        "        :param padding: amount of zero padding, default 1.\n",
        "        :param bias: true to use bias, false to not.\n",
        "        \"\"\"\n",
        "        super(ResidualNode, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Apply forward propagation operation.\n",
        "        :param x: Variable, input.\n",
        "        :return: Variable.\n",
        "        \"\"\"\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "class PreactResidualNode(nn.Module):\n",
        "    \"\"\"\n",
        "    Basic computation unit.\n",
        "    Does batchnorm, relu, and convolution (in this order).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1,\n",
        "                 kernel_size=3, padding=1, bias=False):\n",
        "        \"\"\"\n",
        "        Constructor.\n",
        "        Default arguments preserve dimensionality of input.\n",
        "        :param in_channels: input to the node.\n",
        "        :param out_channels: output channels from the node.\n",
        "        :param stride: stride of convolution, default 1.\n",
        "        :param kernel_size: size of convolution kernel, default 3.\n",
        "        :param padding: amount of zero padding, default 1.\n",
        "        :param bias: true to use bias, false to not.\n",
        "        \"\"\"\n",
        "        super(PreactResidualNode, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Apply forward propagation operation.\n",
        "        :param x: Variable, input.\n",
        "        :return: Variable.\n",
        "        \"\"\"\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "class VariableGenomeDecoder(ChannelBasedDecoder):\n",
        "    \"\"\"\n",
        "    Residual decoding with extra integer for type of node inside the phase.\n",
        "    This genome decoder produces networks that are a superset of ResidualGenomeDecoder networks.\n",
        "    \"\"\"\n",
        "    RESIDUAL = 0\n",
        "    PREACT_RESIDUAL = 1\n",
        "    DENSE = 2\n",
        "\n",
        "    def __init__(self, list_genome, channels, repeats=None):\n",
        "        \"\"\"\n",
        "        Constructor.\n",
        "        :param list_genome: list, genome describing the connections in a network, and the type of phase.\n",
        "        :param channels: list, list of tuples describing the channel size changes.\n",
        "        :param repeats: None | list, list of integers describing how many times to repeat each phase.\n",
        "        \"\"\"\n",
        "        phase_types = [gene.pop() for gene in list_genome]\n",
        "        genome_copy = copy(list_genome)  # We can't guarantee the genome won't be changed in the parent constructor.\n",
        "\n",
        "        super().__init__(list_genome, channels, repeats=repeats)\n",
        "\n",
        "        if self._model is not None:\n",
        "            return  # Exit if the parent constructor set the model.\n",
        "\n",
        "        # Adjust the types for repeats and inactive phases.\n",
        "        self._types = self.adjust_types(genome_copy, phase_types)\n",
        "\n",
        "        phases = []\n",
        "        for idx, (gene, (in_channels, out_channels), phase_type) in enumerate(zip(self._genome,\n",
        "                                                                                  self._channels,\n",
        "                                                                                  self._types)):\n",
        "            if phase_type == self.RESIDUAL:\n",
        "                phases.append(ResidualPhase(gene, in_channels, out_channels, idx))\n",
        "\n",
        "            elif phase_type == self.PREACT_RESIDUAL:\n",
        "                phases.append(ResidualPhase(gene, in_channels, out_channels, idx, preact=True))\n",
        "\n",
        "            elif phase_type == self.DENSE:\n",
        "                phases.append(DensePhase(gene, in_channels, out_channels, idx))\n",
        "\n",
        "            else:\n",
        "                raise NotImplementedError(\"Phase type corresponding to {} not implemented.\".format(phase_type))\n",
        "\n",
        "        self._model = nn.Sequential(*self.build_layers(phases))\n",
        "\n",
        "    def adjust_types(self, genome, phase_types):\n",
        "        \"\"\"\n",
        "        Get only the phases that are active.\n",
        "        Similar to ResidualDecoder.get_effective_genome but we need to consider phases too.\n",
        "        :param genome: list, list of ints\n",
        "        :param phase_types: list,\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        effective_types = []\n",
        "\n",
        "        for idx, (gene, phase_type) in enumerate(zip(genome, phase_types)):\n",
        "            if phase_active(gene):\n",
        "                for _ in range(self._repeats[idx]):\n",
        "                    effective_types.append(*phase_type)\n",
        "\n",
        "        return effective_types\n",
        "\n",
        "    def get_model(self):\n",
        "        return self._model\n",
        "\n",
        "\n",
        "class DenseGenomeDecoder(ChannelBasedDecoder):\n",
        "    \"\"\"\n",
        "    Genetic CNN genome decoder with residual bit.\n",
        "    \"\"\"\n",
        "    def __init__(self, list_genome, channels, repeats=None):\n",
        "        \"\"\"\n",
        "        Constructor.\n",
        "        :param list_genome: list, genome describing the connections in a network.\n",
        "        :param channels: list, list of tuples describing the channel size changes.\n",
        "        :param repeats: None | list, list of integers describing how many times to repeat each phase.\n",
        "        \"\"\"\n",
        "        super().__init__(list_genome, channels, repeats=repeats)\n",
        "\n",
        "        if self._model is not None:\n",
        "            return  # Exit if the parent constructor set the model.\n",
        "\n",
        "        # Build up the appropriate number of phases.\n",
        "        phases = []\n",
        "        for idx, (gene, (in_channels, out_channels)) in enumerate(zip(self._genome, self._channels)):\n",
        "            phases.append(DensePhase(gene, in_channels, out_channels, idx))\n",
        "\n",
        "        self._model = nn.Sequential(*self.build_layers(phases))\n",
        "\n",
        "    @staticmethod\n",
        "    def get_effective_genome(genome):\n",
        "        \"\"\"\n",
        "        Get only the parts of the genome that are active.\n",
        "        :param genome: list, represents the genome\n",
        "        :return: list\n",
        "        \"\"\"\n",
        "        return [gene for gene in genome if phase_active(gene)]\n",
        "\n",
        "    def get_model(self):\n",
        "        \"\"\"\n",
        "        :return: nn.Module\n",
        "        \"\"\"\n",
        "        return self._model\n",
        "\n",
        "\n",
        "class DensePhase(nn.Module):\n",
        "    \"\"\"\n",
        "    Phase with nodes that operates like DenseNet's bottle necking and growth rate scheme.\n",
        "    Refer to: https://arxiv.org/pdf/1608.06993.pdf\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, gene, in_channels, out_channels, idx):\n",
        "        \"\"\"\n",
        "        Constructor.\n",
        "        :param gene: list, element of genome describing connections in this phase.\n",
        "        :param in_channels: int, number of input channels.\n",
        "        :param out_channels: int, number of output channels.\n",
        "        :param idx: int, index in the network.\n",
        "        \"\"\"\n",
        "        super(DensePhase, self).__init__()\n",
        "\n",
        "        self.in_channel_flag = in_channels != out_channels  # Flag to tell us if we need to increase channel size.\n",
        "        self.out_channel_flag = out_channels != DenseNode.t\n",
        "        self.first_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1 if idx != 0 else 3, stride=1, bias=False)\n",
        "        self.dependency_graph = ResidualPhase.build_dependency_graph(gene)\n",
        "\n",
        "        channel_adjustment = 0\n",
        "\n",
        "        for dep in self.dependency_graph[len(gene) + 1]:\n",
        "            if dep == 0:\n",
        "                channel_adjustment += out_channels\n",
        "\n",
        "            else:\n",
        "                channel_adjustment += DenseNode.t\n",
        "\n",
        "        self.last_conv = nn.Conv2d(channel_adjustment, out_channels, kernel_size=1, stride=1, bias=False)\n",
        "\n",
        "        nodes = []\n",
        "        for i in range(len(gene)):\n",
        "            if len(self.dependency_graph[i + 1]) > 0:\n",
        "                channels = self.compute_channels(self.dependency_graph[i + 1], out_channels)\n",
        "                nodes.append(DenseNode(channels))\n",
        "\n",
        "            else:\n",
        "                nodes.append(None)\n",
        "\n",
        "        self.nodes = nn.ModuleList(nodes)\n",
        "        self.out = nn.Sequential(\n",
        "            self.last_conv,\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_channels(dependency, out_channels):\n",
        "        \"\"\"\n",
        "        Compute the number of channels incoming to a node.\n",
        "        :param dependency: list, nodes that a particular node gets input from.\n",
        "        :param out_channels: int, desired number of output channels from the phase.\n",
        "        :return: int\n",
        "        \"\"\"\n",
        "        channels = 0\n",
        "        for d in dependency:\n",
        "            if d == 0:\n",
        "                channels += out_channels\n",
        "\n",
        "            else:\n",
        "                channels += DenseNode.t\n",
        "\n",
        "        return channels\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.in_channel_flag:\n",
        "            x = self.first_conv(x)\n",
        "\n",
        "        outputs = [x]\n",
        "\n",
        "        for i in range(1, len(self.nodes) + 1):\n",
        "            if not self.dependency_graph[i]:  # Empty dependencies, no output to give.\n",
        "                outputs.append(None)\n",
        "\n",
        "            else:\n",
        "                # Call the node on the depthwise concatenation of its inputs.\n",
        "                outputs.append(self.nodes[i - 1](torch.cat([outputs[j] for j in self.dependency_graph[i]], dim=1)))\n",
        "\n",
        "        if self.out_channel_flag and 0 in self.dependency_graph[len(self.nodes) + 1]:\n",
        "            # Get the last nodes in the phase and change their channels to match the desired output.\n",
        "            non_zero_dep = [dep for dep in self.dependency_graph[len(self.nodes) + 1] if dep != 0]\n",
        "\n",
        "            return self.out(torch.cat([outputs[i] for i in non_zero_dep] + [outputs[0]], dim=1))\n",
        "\n",
        "        if self.out_channel_flag:\n",
        "            # Same as above, we just don't worry about the 0th node.\n",
        "            return self.out(torch.cat([outputs[i] for i in self.dependency_graph[len(self.nodes) + 1]], dim=1))\n",
        "\n",
        "        return self.out(torch.cat([outputs[i] for i in self.dependency_graph[len(self.nodes) + 1]]))\n",
        "\n",
        "\n",
        "class DenseNode(nn.Module):\n",
        "    \"\"\"\n",
        "    Node that operates like DenseNet layers.\n",
        "    Refer to: https://arxiv.org/pdf/1608.06993.pdf\n",
        "    \"\"\"\n",
        "    t = 64  # Growth rate fixed at 32 (a hyperparameter, although fixed in paper)\n",
        "    k = 4  # Growth rate multiplier fixed at 4 (not a hyperparameter, this is from the definition of the dense layer).\n",
        "\n",
        "    def __init__(self, in_channels):\n",
        "        \"\"\"\n",
        "        Constructor.\n",
        "        Only needs number of input channels, everything else is automatic from growth rate and DenseNet specs.\n",
        "        :param in_channels: int, input channels.\n",
        "        \"\"\"\n",
        "        super(DenseNode, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels, self.t * self.k, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(self.t * self.k),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.t * self.k, self.t, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "def phase_active(gene):\n",
        "    \"\"\"\n",
        "    Determine if a phase is active.\n",
        "    :param gene: list, gene describing a phase.\n",
        "    :return: bool, true if active.\n",
        "    \"\"\"\n",
        "    # The residual bit is not relevant in if a phase is active, so we ignore it, i.e. gene[:-1].\n",
        "    return sum([sum(t) for t in gene[:-1]]) != 0\n",
        "\n",
        "\n",
        "class GCNNGenomeDecoder(Decoder):\n",
        "    \"\"\"\n",
        "    Original genetic CNN genome from: https://arxiv.org/abs/1703.01513\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, list_genome):\n",
        "        super().__init__(list_genome)\n",
        "        pass\n",
        "\n",
        "    def get_model(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class DONGenomeDecoder(Decoder):\n",
        "    \"\"\"\n",
        "    'Double Or Nothing genome' decoder.\n",
        "    DON refers to the channel size strategy which either doubles or does before a phase.\n",
        "    Also defines residual as ResidualGenome does.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, list_genome):\n",
        "        super().__init__(list_genome)\n",
        "        pass\n",
        "\n",
        "    def get_model(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class Identity(nn.Module):\n",
        "    \"\"\"\n",
        "    Adding an identity allows us to keep things general in certain places.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Identity, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x"
      ],
      "metadata": {
        "id": "i87nl5eGp2fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_decoder(decoder_str, genome, channels, repeats=None):\n",
        "    \"\"\"\n",
        "    Construct the appropriate decoder.\n",
        "    :param decoder_str: string, refers to what genome scheme we're using.\n",
        "    :param genome: list, list of genomes.\n",
        "    :param channels: list, list of channel sizes.\n",
        "    :param repeats: None | list, how many times to repeat each phase.\n",
        "    :return: evolution.ChannelBasedDecoder\n",
        "    \"\"\"\n",
        "    if decoder_str == \"residual\":\n",
        "        return ResidualGenomeDecoder(genome, channels, repeats=repeats)\n",
        "\n",
        "    if decoder_str == \"swapped-residual\":\n",
        "        return ResidualGenomeDecoder(genome, channels, preact=True, repeats=repeats)\n",
        "\n",
        "    if decoder_str == \"dense\":\n",
        "        return DenseGenomeDecoder(genome, channels, repeats=repeats)\n",
        "\n",
        "    if decoder_str == \"variable\":\n",
        "        return VariableGenomeDecoder(genome, channels, repeats=repeats)\n",
        "\n",
        "    raise NotImplementedError(\"Decoder {} not implemented.\".format(decoder_str))"
      ],
      "metadata": {
        "id": "Srd9Y05npZEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EvoNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "    Entire network.\n",
        "    Made up of Phases.\n",
        "    \"\"\"\n",
        "    def __init__(self, genome, channels, out_features, data_shape, decoder=\"residual\", repeats=None):\n",
        "        \"\"\"\n",
        "        Network constructor.\n",
        "        :param genome: depends on decoder scheme, for most this is a list.\n",
        "        :param channels: list of desired channel tuples.\n",
        "        :param out_features: number of output features.\n",
        "        :param decoder: string, what kind of decoding scheme to use.\n",
        "        \"\"\"\n",
        "        super(EvoNetwork, self).__init__()\n",
        "\n",
        "        assert len(channels) == len(genome), \"Need to supply as many channel tuples as genes.\"\n",
        "        if repeats is not None:\n",
        "            assert len(repeats) == len(genome), \"Need to supply repetition information for each phase.\"\n",
        "\n",
        "        self.model = get_decoder(decoder, genome, channels, repeats).get_model()\n",
        "\n",
        "        #\n",
        "        # After the evolved part of the network, we would like to do global average pooling and a linear layer.\n",
        "        # However, we don't know the output size so we do some forward passes and observe the output sizes.\n",
        "        #\n",
        "\n",
        "        out = self.model(torch.autograd.Variable(torch.zeros(1, channels[0][0], *data_shape)))\n",
        "        shape = out.data.shape\n",
        "\n",
        "        self.gap = nn.AvgPool2d(kernel_size=(shape[-2], shape[-1]), stride=1)\n",
        "\n",
        "        shape = self.gap(out).data.shape\n",
        "\n",
        "        self.linear = nn.Linear(shape[1] * shape[2] * shape[3], out_features)\n",
        "\n",
        "        # We accumulated some unwanted gradient information data with those forward passes.\n",
        "        self.model.zero_grad()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward propagation.\n",
        "        :param x: Variable, input to network.\n",
        "        :return: Variable.\n",
        "        \"\"\"\n",
        "        x = self.gap(self.model(x))\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        return self.linear(x), None"
      ],
      "metadata": {
        "id": "GQIlMp7qpTZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform, valid_transform, test_transform = _data_transforms_cifar10(cutout= False)"
      ],
      "metadata": {
        "id": "-xsoMoNBlUPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4BqXNvBqt4vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data =\"/content/\" #default='./content, help='location of the data corpus'"
      ],
      "metadata": {
        "id": "zYJgvpMbmuXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = torchvision.datasets.CIFAR10(root=data, train=True, download=True, transform=train_transform)\n",
        "valid_data = torchvision.datasets.CIFAR10(root=data, train=False, download=True, transform=valid_transform)"
      ],
      "metadata": {
        "id": "a1-xzp7Pm11-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149,
          "referenced_widgets": [
            "e7b488a699f34e839d438572f93cf194",
            "b90be05d2ff74f658f669df5b94f464f",
            "7a5a92c324774bfca676389c4bf4b608",
            "a93f478fa5614288ba638b7a1ec1771e",
            "f45b076574c440519de0a0cce474dc10",
            "a763d2b41fc74131a6859c1c9133d74a",
            "09d5c846c1fb44e78e33f737181bb6f9",
            "1ef12fb137034500891d4500b4f8c21d",
            "92198fe269f54454b08f59f328744443",
            "5329a5f2ba3346c5b9b147d2c92d3339",
            "3359862780de4ab2af3c9b1195646511"
          ]
        },
        "outputId": "1439ab24-042f-4f9b-b245-f5ade7ae8f84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7b488a699f34e839d438572f93cf194"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/cifar-10-python.tar.gz to /content/\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IKADy4E5Cn4",
        "outputId": "e1a9c6d7-d10a-45d9-c444-cda15b23ec82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset CIFAR10\n",
              "    Number of datapoints: 50000\n",
              "    Root location: /content/\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               RandomCrop(size=(32, 32), padding=4)\n",
              "               RandomHorizontalFlip(p=0.5)\n",
              "               ToTensor()\n",
              "               Normalize(mean=[0.49139968, 0.48215827, 0.44653124], std=[0.24703233, 0.24348505, 0.26158768])\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DN-YT8DP5PSz",
        "outputId": "0b641255-e272-486b-e0a3-baed645062fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset CIFAR10\n",
              "    Number of datapoints: 10000\n",
              "    Root location: /content/\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "               Normalize(mean=[0.49139968, 0.48215827, 0.44653124], std=[0.24703233, 0.24348505, 0.26158768])\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_queue = torch.utils.data.DataLoader(\n",
        "        train_data, batch_size=256, shuffle=True, pin_memory=True, num_workers=2)"
      ],
      "metadata": {
        "id": "mxeTtBWfnxlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_queue = torch.utils.data.DataLoader(\n",
        "        valid_data, batch_size=128, shuffle=False, pin_memory=True, num_workers=2)"
      ],
      "metadata": {
        "id": "WqamWqKGnzzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genome = [[[1], [0, 0], [0, 0, 1], [1, 0, 1, 1], [1, 0, 0, 0, 0], [0]], [[0], [0, 1], [1, 1, 1], [0, 1, 1, 1], [0, 1, 0, 1, 1], [0]], [[1], [0, 0], [0, 1, 0], [1, 1, 0, 0], [0, 0, 1, 0, 0], [0]]]"
      ],
      "metadata": {
        "id": "ZsUHxGTSooUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "channels = [(3, 128), (128, 128), (128, 128)]"
      ],
      "metadata": {
        "id": "roc2Ey-4pD4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = EvoNetwork(genome, channels, 10, (32, 32), decoder='dense')"
      ],
      "metadata": {
        "id": "TZsHHAKTpGyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\""
      ],
      "metadata": {
        "id": "Pk0SgU9JrPTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = net.to(device)"
      ],
      "metadata": {
        "id": "sTyS3PepqHOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 600"
      ],
      "metadata": {
        "id": "0L3jGpW_rBn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = filter(lambda p: p.requires_grad, net.parameters())"
      ],
      "metadata": {
        "id": "3xD2ccWcrHj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion.to(device)"
      ],
      "metadata": {
        "id": "NEldYTYnrOBN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c18c5625-b753-41a8-89d4-c294b71cef9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CrossEntropyLoss()"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.025\n",
        "momentum = 0.9\n",
        "weight_decay = 3e-4\n",
        "min_learning_rate = 0.0"
      ],
      "metadata": {
        "id": "9btZMP63rYx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(parameters,\n",
        "                          lr=learning_rate,\n",
        "                          momentum=momentum,\n",
        "                          weight_decay=weight_decay)"
      ],
      "metadata": {
        "id": "jR1-cmg8rVMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs, eta_min=min_learning_rate)"
      ],
      "metadata": {
        "id": "3jjDAbIVroL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "droprate = 0\n",
        "epochs = 600"
      ],
      "metadata": {
        "id": "ZIimmM6ury1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_queue, net, criterion, optimizer):\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    auxiliary = False\n",
        "    auxiliary_weight = 0.4\n",
        "    grad_clip = 5\n",
        "    report_freq = 50\n",
        "\n",
        "    for step, (inputs, targets) in enumerate(train_queue):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs, outputs_aux = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        if auxiliary:\n",
        "            loss_aux = criterion(outputs_aux, targets)\n",
        "            loss += auxiliary_weight * loss_aux\n",
        "\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), grad_clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        if step % report_freq == 0:\n",
        "            logging.info('train %03d %e %f', step, train_loss/total, 100.*correct/total)\n",
        "\n",
        "    logging.info('train acc %f', 100. * correct / total)\n",
        "\n",
        "    return train_loss/total, 100.*correct/total"
      ],
      "metadata": {
        "id": "AW_TeSFEr9o1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def infer(valid_queue, net, criterion):\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    report_freq = 50\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for step, (inputs, targets) in enumerate(valid_queue):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs, _ = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            if step % report_freq == 0:\n",
        "                logging.info('valid %03d %e %f', step, test_loss/total, 100.*correct/total)\n",
        "\n",
        "    acc = 100.*correct/total\n",
        "    logging.info('valid acc %f', 100. * correct / total)\n",
        "\n",
        "    return test_loss/total, acc"
      ],
      "metadata": {
        "id": "cA1sdDgnsRdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save(model, model_path):\n",
        "    torch.save(model.state_dict(), model_path)"
      ],
      "metadata": {
        "id": "mOoRA20ZsjE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "error = []"
      ],
      "metadata": {
        "id": "RViPhx7TBjl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(40):\n",
        "        scheduler.step()\n",
        "        print('epoch %d lr %e' % (epoch, scheduler.get_last_lr()[0]))\n",
        "        net.droprate = droprate * epoch / epochs\n",
        "\n",
        "        train(train_queue, net, criterion, optimizer)\n",
        "        _, valid_acc = infer(valid_queue, net, criterion)\n",
        "        error.append(100 - valid_acc)\n",
        "        print(valid_acc)\n",
        "        if valid_acc > best_acc:\n",
        "            save(net, '/content/weights.pt')\n",
        "            best_acc = valid_acc"
      ],
      "metadata": {
        "id": "YZw6AgH0ru4z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78a14f8a-2f2b-4680-c2b3-83d47b7a5f00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 lr 2.499983e-02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56.5\n",
            "epoch 1 lr 2.499931e-02\n",
            "71.73\n",
            "epoch 2 lr 2.499846e-02\n",
            "63.53\n",
            "epoch 3 lr 2.499726e-02\n",
            "74.64\n",
            "epoch 4 lr 2.499572e-02\n",
            "79.9\n",
            "epoch 5 lr 2.499383e-02\n",
            "81.8\n",
            "epoch 6 lr 2.499160e-02\n",
            "83.15\n",
            "epoch 7 lr 2.498904e-02\n",
            "82.03\n",
            "epoch 8 lr 2.498612e-02\n",
            "83.46\n",
            "epoch 9 lr 2.498287e-02\n",
            "85.56\n",
            "epoch 10 lr 2.497927e-02\n",
            "84.67\n",
            "epoch 11 lr 2.497533e-02\n",
            "85.01\n",
            "epoch 12 lr 2.497105e-02\n",
            "85.74\n",
            "epoch 13 lr 2.496643e-02\n",
            "86.28\n",
            "epoch 14 lr 2.496147e-02\n",
            "87.75\n",
            "epoch 15 lr 2.495616e-02\n",
            "84.87\n",
            "epoch 16 lr 2.495051e-02\n",
            "84.02\n",
            "epoch 17 lr 2.494452e-02\n",
            "87.6\n",
            "epoch 18 lr 2.493819e-02\n",
            "86.03\n",
            "epoch 19 lr 2.493152e-02\n",
            "88.04\n",
            "epoch 20 lr 2.492451e-02\n",
            "87.74\n",
            "epoch 21 lr 2.491716e-02\n",
            "85.8\n",
            "epoch 22 lr 2.490947e-02\n",
            "87.49\n",
            "epoch 23 lr 2.490143e-02\n",
            "86.82\n",
            "epoch 24 lr 2.489306e-02\n",
            "87.98\n",
            "epoch 25 lr 2.488435e-02\n",
            "86.89\n",
            "epoch 26 lr 2.487530e-02\n",
            "87.28\n",
            "epoch 27 lr 2.486590e-02\n",
            "89.7\n",
            "epoch 28 lr 2.485617e-02\n",
            "88.18\n",
            "epoch 29 lr 2.484610e-02\n",
            "87.01\n",
            "epoch 30 lr 2.483570e-02\n",
            "87.14\n",
            "epoch 31 lr 2.482495e-02\n",
            "89.2\n",
            "epoch 32 lr 2.481387e-02\n",
            "85.77\n",
            "epoch 33 lr 2.480245e-02\n",
            "89.52\n",
            "epoch 34 lr 2.479069e-02\n",
            "87.9\n",
            "epoch 35 lr 2.477859e-02\n",
            "88.5\n",
            "epoch 36 lr 2.476616e-02\n",
            "88.44\n",
            "epoch 37 lr 2.475339e-02\n",
            "89.16\n",
            "epoch 38 lr 2.474029e-02\n",
            "88.01\n",
            "epoch 39 lr 2.472685e-02\n",
            "88.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('classic')\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "f9nOzNwJooLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "kyvEsAUeqDno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.array(error)"
      ],
      "metadata": {
        "id": "OgMutnvMor9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "id": "qPPq4izVtOW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7153d7dd-132b-48b7-b039-98776802f342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[43.5  28.27 36.47 25.36 20.1  18.2  16.85 17.97 16.54 14.44 15.33 14.99\n",
            " 14.26 13.72 12.25 15.13 15.98 12.4  13.97 11.96 12.26 14.2  12.51 13.18\n",
            " 12.02 13.11 12.72 10.3  11.82 12.99 12.86 10.8  14.23 10.48 12.1  11.5\n",
            " 11.56 10.84 11.99 11.47]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(40)"
      ],
      "metadata": {
        "id": "_wjIVa8Hoxcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5,8))\n",
        "plt.scatter(x, y, label=\"Error with each epoch\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Error')\n",
        "\n",
        "plt.plot(x, y, ls=\"--\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gmYhy5ipB9x",
        "outputId": "e78e62da-876f-481d-fab0-a48466fca91a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fbb59318af0>]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load('weights.pt')"
      ],
      "metadata": {
        "id": "TqQ7GpiQ4M6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net.load_state_dict(checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fr5aONrq4Q3-",
        "outputId": "b3de7711-c175-4573-8323-cc675fb05185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = net.to(device)"
      ],
      "metadata": {
        "id": "MgtY2_vm8uDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, valid_acc = infer(valid_queue, net, criterion)\n",
        "print(valid_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb26W_Ur6rT5",
        "outputId": "8963903e-f937-4b30-ad52-8e091b352ccb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89.7\n"
          ]
        }
      ]
    }
  ]
}